\documentclass[12pt,a4paper]{report}
\usepackage[12pt]{extsizes}
\usepackage[english,russian]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{geometry} % Меняем поля страницы
 \usepackage{float}
\usepackage[linesnumbered,boxed]{algorithm2e}
\graphicspath{{imgs/}}
\geometry{left=2cm}% левое поле
\geometry{right=1.5cm}% правое поле
\geometry{top=1cm}% верхнее поле
\geometry{bottom=2cm}% нижнее поле
\addto\captionsrussian{\renewcommand{\contentsname}{Содержание}}
\addto\captionsrussian{\renewcommand{\bibname}{Список использованных источников}}
\renewcommand{\baselinestretch}{1.5 }
\renewcommand{\theenumi}{\arabic{enumi}}
\renewcommand{\labelenumi}{\arabic{enumi}}
\renewcommand{\theenumii}{.\arabic{enumii}}
\renewcommand{\labelenumii}{\arabic{enumi}.\arabic{enumii}.}
\renewcommand{\theenumiii}{.\arabic{enumiii}}
\renewcommand{\labelenumiii}{\arabic{enumi}.\arabic{enumii}.\arabic{enumiii}.}
\author{Вадим Кокарев}
\title{Автоматическая интерпретация результатов коллаборативной фильтрации}


\begin{document}
\begin{titlepage}
\par

\begin{center}
{\large
Санкт-Петербургский Государственный Политехнический Университет\\
Институт прикладной математики и механики\\
Кафедра прикладной математики\\

\vspace*{0.5cm}

\begin{flushright}
Диссертация допущена к защите\\
Зав. кафедрой\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \\
\underline{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ } М.Е.Фролов\\
"\underline{ \ \ }"\underline{ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ }
\end{flushright}

\vspace*{2.0cm}

{\Large
  \textbf{
    ДИССЕРТАЦИЯ\\
    на соискание степени МАГИСТРА\\
  }
}
\vspace*{1cm}
\textbf{
  Тема: \emph{автоматическая интерпретация результатов работы рекомендательной системы}\\
}

}

\vspace*{1cm}

\begin{flushleft}
Направление: 01.04.02 - Прикладная математика и информатика\\
Магистерская программа: системное программирование\\
\end{flushleft}

\vspace*{0.2cm}

\begin{flushleft}
Студент--дипломник \hrulefill Кокарев В.В.\\
\vspace*{0.3cm}
Научный руководитель к.ф.-м.н., доцент \hrulefill Иванков А.А.\\
\vspace*{0.3cm}
Рецензент к.ф.-м.н. \hrulefill Пименов В.Ю.\\
\vspace*{0.3cm}
\end{flushleft}
\vspace{0.2em} 

\begin{flushleft}
Консультанты:\\
\vspace*{0.3cm}
по вопросам машинного обучения  к.ф.-м.н. \hrulefill Кураленок И.Е.\\
\vspace*{0.3cm}
по вопросам охраны труда к.т.н., доцент \hrulefill Монашков В.В.\\
\end{flushleft}
\vspace{\fill}

\end{center}
\vfill
\begin{center}
{\large Санкт-Петербург \\ 2015}
\end {center}
\end{titlepage}

\tableofcontents % это оглавление, которое генерируется автоматически
\pagebreak
\chapter{Введение}
В последние годы, четко обозначилась тенденция к росту популярности интернет магазинов. Одним из основных отличий виртуального магазина от реального - ассортимент предлагаемых товаров. В силу физических причин, невозможно представить весь ассортимент товаров в обычном магазине, в отличии от виртуального магазина. С одной стороны неограниченный ассортимент - безусловный плюс виртуальных магазинов, с другой -- он требует от покупателя потратить больше времени на поиск и выбор необходимого товара.

Обычный покупатель, в свою очередь, хочет тратить как можно меньше времени на поиск и выбор товара. С точки зрения покупателя, идеальным был бы сценарий, когда первая же ссылка на главной странице интернет-магазина, приводила бы его на товар, который он бы хотел купить в данный момент.

Данные рассуждения приводят к мысли, что простого поиска 
%% очень много опечаток! нужно пройти спелчекером!
по каталогу и системы фильтров может быть не достаточно для успешного функционирования виртуального магазина. Возможно, не стоит дожидаться, пока пользователь потратит свое время на заполнение форм поиска, а попробовать угадать какой товар интересует пользователя в данную минуту и предложить его. Именно такую задачу и решают рекомендательные системы.

Рекомендательные системы, в первую очередь, предназначены для улучшения жизни конечных пользователей: экономии времени, подбора объективно хорошего товара. С точки зрения продавца, хороша рекомендательная система позволяет продать больше товаров, а так же повысить лояльность пользователей, оценивших скорость покупок в данном магазине.

\section{Способы улучшения качества рекомендаций}
Т.к. от хорошей рекомендательной системы выигрывают все (и покупатель, и продавец), очевидным желанием является улучшения качества рекомендаций.
Метрики, позволяющие оценить качество рекомендаций будут рассмотрены позже, пока, под качеством рекомендаций можно считать $P=\frac{buy}{show}$, где $buy$ - число покупок товаров по рекомендации, $show$ - число показов блока с рекомендациями.

Интуитивно можно выделить несколько направлений, возможно, приводящих к улучшению качества рекомендаций:
\begin{itemize}
\item увеличения объема данных, на которых собирается статистика (далее обучающее множество)
\item улучшение алгоритма формирования рекомендаций
\end{itemize}
Практика показывает, что в большинстве случаев, увеличение объема обучающего множества, действительно, позволяет улучшить качество рекомендаций. Однако, зависимость между мощностью обучающего множества и качеством рекомендаций, как правило, имеет логарифмический характер. Это приводит к тому, что хоть сколько-нибудь значимое изменение качества требует многократного изменения мощности обучающего множества. На практике такое практически невозможно.


Улучшение старого или разработка нового алгоритма формирования рекомендаций - процесс, требующий значительных затрат на исследования. А гарантий, что исследования дадут реальный результат - нет.

В итоге, каждое последующее улучшение качества рекомендаций требует все больших ресурсов, и в конечном итоге дает все меньший практический эффект.
Это приводит к мысли, что  необходимо искать альтернативные способы увеличения числа покупок при том же качестве рекомендаций (при фиксированном алгоритме формирования рекомендаций и фиксированном обучающем множестве).

\section{Неформальная постановка задачи}
Психологи доказали, что люди намного охотнее принимают советы, содержащие обоснование. Т.е. если попробовать объяснять пользователю, почему рекомендательная система считает, что этот товар ему подходит, то пользователь будет позитивнее воспринимать предложенный товар. Так же пользователь может оценить тезис, представленный в рекомендации и в случае, если тезис, с его точки зрения ложный - не тратить время на просмотр товара, который он не купит.
%% откровенно говоря, по-моему здесь перебор с темой лесоповала. Вы же заявляли, что речь пойдет о приложениях для Мобил?
Например, рекомендательная система предлагает купить бензопилу "Лесоруб", обосновывая это тем, что пользователь строит дачный дом. Если пользователь действительно строит дом и у него нет пилы, то он может задуматься, о покупке пилы, если даже не думал об этом ранее. Если пользователь не строит дом или у него есть пила, то он сразу поймет, что данная рекомендация ему не интересна и не будет тратить время на просмотр бесполезного товара.
Теперь рассмотрим того же пользователя и ту же рекомендацию пилы, но предположим, что обоснование рекомендации звучит так: "Данная пила лучше, чем "Лесоруб-0".
Ситуация получается диаметрально противоположной той, что была описана в предыдущем примере. Если у пользователя нет пилы, то он скорее всего пройдет мимо, т.к. информация о том, что какая-то пила лучше какой-то другой пилы для него не несет полезной информации. А если же, у пользователя есть пила "Лесоруб-0", то он может заинтересоваться более новой моделью.
Данные примеры показывают, что один и тот же товар, может быть расценен по разному одним и тем же пользователем, в зависимости от представленного обоснования. Т.е. можно предполагать, что правильное объяснение рекомендаций, действительно может улучшить общее качество рекомендательной системы.

Целью данной работы является разработка алгоритма, способного найти наиболее вероятную причину, по которой алгоритм формирования рекомендаций выбрал конкретный товар для конкретного пользователя.

\section{Примеры успешных продуктов}
Приведем несколько примеров, как коммерческих, так и некоммерческих рекомендательных систем.
Популярный сайт kinopoisk.ru, посвященный новинкам кинематографа,  (Рис. $\ref{ris:ex})$ предлагает к просмотру фильмы, обосновывая свои рекомендации схожестью рекомендуемого и уже хорошо известного фильма.
Другой сайт imhonet.ru предлагает к просмотру фильм, обосновывая рекомендации схожестью вкусов пользователей.
\begin{figure}[H]
\begin{minipage}[h]{0.49\linewidth}
\center{\includegraphics[width=0.8\linewidth]{imhonet} \\ imhonet.ru}
\end{minipage}
\hfill
\begin{minipage}[h]{0.49\linewidth}
\center{\includegraphics[width=0.9\linewidth]{kinopoisk} \\ kinopoisk.ru}
\end{minipage}
\caption{Примеры рекомендаций на различных сайтах}
\label{ris:ex}
\end{figure}

Из данных примеров видно, что даже очень крупные и популярные сайты не пренебрегают объяснениями причин рекомендаций. Однако, все объяснения являются статичными и не зависят от того, какой товар какому пользователю предлагается.


\chapter{Задача объяснения рекомендаций}
\newtheorem{Def}{Определение}
\begin{Def}
Признаковое описание объекта --- $x = f(e),$ где $e \in \mathbb{D},$ - объект из некоторой предметной области $\mathbb{D}$, а $f: \mathbb{D}  \to \mathbb{R}^n$.
\end{Def}

\begin{Def}
Признак --- проекция признакового описания объекта $e \in \mathbb{D}$ на одну из орт. Для простоты, будем обозначать за $f_i(e)$ - проекцию $f(e)$ на орт $i$.
\end{Def}

Далее будем отождествлять сам объект $x \in \mathbb{D}$ с его признаковым описанием $f(e)$, это необходимо, для того, чтобы объекты из произвольной предметной области имели единую формализацию.

Обычно алгоритм формирования рекомендаций $A$ можно описать следующим образом:


\begin{algorithm}[H]
\SetAlgoLined
\KwData{$u \in \mathbb{U}$ - конкретный пользователь, $\mathbb{I}$ - множество товаров, $f:\mathbb{U} \times \mathbb{I} \to \mathbb{R}^n$ - признаковое описание пары пользователь-товар, $m \in \mathbb{N}$ - желаемое число рекомендаций}
\KwResult{$\{(i_j, score)\}_{j=1}^{k}$, где $k \le m$, $score \in \mathbb{R}$ - оценка рейтинга товара $i_j \in \mathbb{I}$ для пользователя $u$}

results = SortedSet()

\For{$i \in I$} {
	
	$results += (i, getScore(f(u, i)))$
	
}

\textbf{return} $head(results, m$ --- получение m товаров с наибольшим значением $score$

\caption{Псевдокод общего алгоритма работы рекомендательной системы.}
\label{alg:GENERALRS}
\end{algorithm}

Реализация функции $getScore$, оценивающей рейтинг товара для конкретного пользователя, зависит от конкретной рекомендательной системы.

\section{Формальная постановка задачи}
Пусть дан некоторый алгоритм построения рекомендаций $A$ ,  множество текстовых меток $\mathbb{S}$, множество пользователей $\mathbb{U}$ и множество товаров $\mathbb{I}$.

Задача: При фиксированном алгоритме формирования рекомендаций $A$,
%% мне кажется, что это очень плохо, когда Вы по ходу изложения меняете семантику переменных, здесь речь о D!
 найти такое отображение $D: \mathbb{U} \times \mathbb{I} \to \mathbb{S}$, сопоставляющее паре пользователь-товар  текстовую метку, такое, что  $ClickRate \to \max$, где $ClickRate$ - отношение числа кликов по блоку с рекомендацией к общему числу показов блока. Т.е. необходимо для каждой конкретной рекомендации найти 
 %% я бы "человеко" убрал
 интерпретируемое объяснение. 

\section{Гипотеза о роли признака}
\begin{Def}
Вклад признака $f_j$ в оценку рейтинга товара $i \in \mathbb{I}$ для пользователя $u \in \mathbb{U}$ --- $\delta A_{f_j,i,u} = getScore_A(f(u, j)) - getScore_{A_j}(f(u, i))$, где $getScore_A$ - функция оценки рейтинга, используемая в алгоритме формирования рекомендаций $A$, $getScore_{A_j}$ - функция оценки рейтинга, построенная аналогично $getScore_{A}$, но не использующая признак $f_j$.
\end{Def}
Примем следующую гипотезу: признак, вносящий наибольший вклад в оценку рейтинга, сильно связан с причиной рекомендации.
Т.е. если дано отображение $M': \mathbb{F} \to \mathbb{S}$, где $\mathbb{F}$ - множество признаков, то задача объяснения рекомендаций сводится к выявлению признака, вносящего наибольший вклад в оценку рейтинга рекомендации.

В общем случае, можно рассмотреть отображение $M: \mathbb{F} \times \dots \mathbb{F} \to \mathbb{S}$. Т.е. можно пытаться интерпретировать не один признак, а сразу группу признаков.

На практике количество признаков может быть очень велико (в рассматриваемой задаче около 500 признаков), поэтому будем рассматривать отображение $M$ на некотором подмножестве $\mathbb{F} \times \mathbb{F}$, т.е. часть признаков будем оставлять без интерпретации.

\section{Общий алгоритм объяснения рекомендаций}
Если принять гипотезу о роли признака, представленную в предыдущем пункте, то задача объяснения рекомендаций может быть решена с помощью следующего алгоритма:


\begin{algorithm}[H]
\SetAlgoLined
\KwData{$u \in \mathbb{U}$ - конкретный пользователь, $i \in \mathbb{I}$ - рекомендованный товар, $f:\mathbb{U} \times \mathbb{I} \to \mathbb{R}^n$ - признаковое описание пары пользователь-товар, $A$ - алгоритм формирования рекомендаций, $M:\mathbb{F} \to \mathbb{S}$ - интерпретация признаков}
\KwResult{$s \in \mathbb{S}$ - объяснение рекомендации}

$max = (1, \delta A_{f_1, i, u})$ //max - пара, состоящая из номера признака и его вклада

\For{$j = 2,\dots, n$} {
	
	max = $getMax((j, \delta A_{f_j, i, u}), max)$
	
}
%% что за feature???
\textbf{return} $M(max[0])$ // $max[0]$ - номер признака с наибольшим вкладом

\caption{Псевдокод общего алгоритма объяснения рекомендаций.}
\label{alg:GENERALENT}
\end{algorithm}

Т.о. что бы решить поставленную задачу необходимо решить 2 подзадачи:

\begin{itemize}
\item вычислить вклада признака в рейтинг
%% задать отношение частичного порядка?
%! строго говоря, отношение линейного порядка, т.к. у нас нет несравнимых элементов
\item задать отношение линейного порядка на множестве вкладов (реализовано функцией $getMax$).
\end{itemize}

Начнем с решения задачи вычисления абсолютного вклада признака в рейтинг. Очевидно, что к решению данной задачи можно подойти с двух сторон:
\begin{itemize}
\item рассматривать рекомендательную систему как черный ящик (т.е. абстрагироваться от конкретной реализации метода getScore)
\item рассматривать рекомендательную систему как прозрачный ящик (т.е. использовать знания о структуре функции getScore).
\end{itemize}

Если рассматривать алгоритм формирования рекомендаций как черный ящик, то стоит следующая задача: не зная структуру функции getScore (далее будем называть ее решающей функцией), оценить вклад, вносимый каждым из признаков.
Данная формулировка практически точно совпадает с формулировкой задачи отбора признаков (feature selection) \cite{AdvFeatureSelectionResearch}, которая часто решается в машинном обучении для удаления признаков, которые вносят слабый вклад в оценку рейтинга. Это позволяет сократить время, требующиеся на подбор параметров, уменьшить время формирования списка рекомендаций, а так же уменьшить вероятность переобучения \cite{Voron}.

\section{Задача отбора признаков}
Существуют различные подходы к решению задачи отбора признаков (feature selection), например, фильтрационные модели (filter model), основанные на ReliefF \cite{ReliefF}, Fisher score \cite{Fisher} и Information Gain \cite{Gain}.

Однако, существующие подходы вычисляют вклад признака, усредненный по всем парам пользователь-товар, а в рассматриваемой задаче требуется понять насколько велик вклад признака для конкретной пары.
Т.о. существующие алгоритмы не могут быть применены к поставленной задаче.

\section{Обзор рекомендательных систем}
Попробуем решить задачу вычисления вклада признака, рассматривая рекомендательную систему, как прозрачный ящик (используя знания о структуре функции $getScore$). Для этого необходимо рассмотреть какие существуют подходы к построению рекомендательных систем.

\subsection{Классические рекомендательные системы}
Одними из наиболее ранних рекомендательных систем, получивших широкое распространение, стали рекомендательные системы,
%% ориентированные на использование множество признаков, описывающих пользователей 
%! исправил, но в русской литературе принято переводить как "основанные на пользователе"
 основанные на ипользовании признаков, описывающих пользователя (user-based) \cite{Ubrs}. В рекомендательных системах, принадлежащих данному классу, функция
\begin{equation*}
getScore(u, i) = \frac{\sum_{u' \in \mathbb{U}_i} \rho(f(u), f(u')) r_{u'_i}}{\sum_{u' \in \mathbb{U}_i} \rho(f(u), f(u')) },
\end{equation*}
где $f$ - признаковое описание пользователя, $\mathbb{U}_i$ -  множество пользователей, для которых известны $r_{u'_i}$ --- рейтинг товара $i \in \mathbb{I} $ для пользователя $u' \in \mathbb{U}$ (например, пользователь сам выставил оценку данному товару на веб-интерфейсе). Т.е. данные алгоритмы оценивают рейтинг товара для конкретного пользователя, как взвешенную сумму известных рейтингов для данного товара, а в качестве весов использует меру близости между двумя пользователями. Т.к. обычно про пользователей известна только история действий на сайте, то в качестве признакового описания пользователя часто берут вектор, размерностью $|\mathbb{I}|$, у которого на $i$-й позиции стоит $r_{u_i}$, если данная величина известна. А в качестве расстояния часто выбирают косинусное расстояние \cite{Cos}.

Аналогично строятся рекомендательные системы, основанные на товаре (content-based), но основная идея заключается в том, что бы рекомендовать пользователю товары, похожие на те, что он уже высоко оценил \cite{Cbrs}.

Так же к классическим рекомендательным системам относят системы, основанные на правилах (knowledge-based). В таких рекомендательных системах заранее задается набор правил, которые полностью описывают процесс формирования рекомендаций \cite{Know}.
%% дак это ведь определяются подмножества на декартовом произведении товаров и пользователе? и эти подмножества снабжаются детерминированной/вероятностной мерой
%! не совсем так. Вести речь о вероятностной мере имеет смысл в терминах решения задачи классификации (когда  мы оцениваем вероятность того, что пользователю понравится товар). В данном случае речь идет о том, что товар попадает в список рекомендованных, если выполняется хотя бы одни из заранее заданных предикатов (правил). Модель к математике имеет отношение весьма посредственное, но из-за ее распростаренности не упомянуть про нее нельзя. Конечно, я могу принять данную правку, но для человека, занимающимя машинным обучением она будет выглядеть притянутой за уши
 Примерами таких правил могут быть: "не рекомендовать боевики женщинам старше 38", "не рекомендовать фильмы с оценкой ниже 6" и т.д. 

Очевидно, что для рассмотренных рекомендательных систем, решать задачу объяснения рекомендаций не имеет смысла, т.к. причина, по которой алгоритм выбрал тот или иной товар уже заложена в самом алгоритме.
\subsection{Матричная факторизация}
Данный метод обрел свою популярность после успеха на Netflix Cup (соревнование по построению рекомендательной системы фильмов для сайта netflix.com). В данном соревновании необходимо было предсказать, какой рейтинг (от 1 до 5) поставит конкретный человек конкретному фильму, зная все оценки, которые когда-либо были поставлены на сайте.

Пусть $\{\mathcal{U}\}_{i=0}^{UserCount}$  - индексированное множество пользователей, когда-либо поставивших оценку, $\{\mathcal{I}\}_{i=0}^{ItemCount}$ - индексированное множество товаром, имеющих хотя бы одну оценку.
%% опять семантика переменных "поехала"
 Заранее имеется набор троек $\mathcal{L} = \{(u, a, r)\}$, где $u \in \mathcal{U}, a \in \mathcal{I}, r \in [0, 5]$. Так же дан набор троек $\mathcal{T} = \{(u, a, r)\}$, который нельзя использовать для подбора параметров модели. Необходимо для каждой пары $\{u,a\} \notin \mathcal{L|_{\mathcal{U}\times\mathcal{I}}}$ предсказать значение рейтинга $\tilde{r}$. При этом необходимо минимизировать некоторый функционал качества предсказания $T(\mathcal{T})$. В качестве функционала качества может выступать, например, 
\begin{equation*}
RMSE = \sqrt{\frac{\sum_{(u, a, r) \in \mathcal{T}}(\tilde{r}_{u,a} - r)^2}{|\mathcal{T}|}}.
\end{equation*}


Пусть $r_{ij}$ - рейтинг, который поставил пользователь $u_i \in \mathcal{U}$ фильму $a_j \in \mathcal{I}$. Основная идея метода состоит в том, что $r_{ij}$ можно представить следующим образом:
\begin{equation*}
r_{ij} = \mu + bias_{u_i} + bias_{a_j} + q_{a_j}^Tp_{u_i}
\end{equation*}
где $\mu \in \mathbb{R}, bias \in \mathbb{R}, q,p \in \mathbb{R}^k, k - $ параметр модели.
Все величины подбираются методами численной оптимизации, но их можно интерпретировать следующий образом:
\begin{itemize}
\item $\mu$ - общее смещение модели, средний рейтинг всех товаров среди всех пользователей
\item $bias_u, bias_m$ - среднее смещений рейтинга, выставленного данным пользователем (или данному товару) относительно $\mu$
\item $p$ - вектор-строка, $q$ - вектор-столбец, каким-то образом описывающие конкретного пользователя/товар.
\end{itemize}

Метод получил свое название, благодаря оригинальному методу обучения, в котором  исходные тройки представляются в виде матрицы: каждому пользователю соответствует строка, каждому товару - столбец, а на пересечении строки и столбца стоит рейтинг, если он известен. Далее проводится разложение данной матрицы на две компоненты $P$ и $Q$, которые состоят из векторов $p$ и $q$ соответственно.

Фактически, вектора $p$ и $q$ являются признаковыми описаниями для пользователя и приложения. А функция $getScore$ возвращает значение $r_{ij}$. Однако, для такого рода признакового описания очень сложно подобрать отображение $M$ (сопоставляющее признаку текстовую интерпретацию), т.к. семантика каждого из признаков не ясна. Поэтому данные типы рекомендательных систем так же исключаются из дальнейшего рассмотрения.
\subsection{Рекомендательные системы, основанные на решении задачи классификации}

Рассмотрим задачу бинарной классификации:
%% и опять смысл переменных поплыл
Пусть $\mathbb{X}$ - множество объектов, $\mathbb{Y} = \{-1, +1\}$ - множество меток классов. Предполагается, что существует неизвестное вероятностное распределение на множестве $\mathbb{X} \times \mathbb{Y}$ с плотностью $p(x, y)$, из которого случайно и независимо выбираются $l$ наблюдений $X^l = (x_j, y_j)_{j=1}^l	$. Выборка $X^l$ случайным образом делится на две непересекающиеся подвыборки $T$ и $L$ с длинами $m$ и $k$ соответственно. Требуется, используя только элементы выборки $L$, построить алгоритм $A:\mathbb{X} \to \mathbb{Y}$, способный оценить вероятность $P(x \in +1)$. При этом так же требуется минимизировать значение некоторого функционала ошибки (функция потерь) на элементах выборки $T$, т.е. $A = \arg \min_{A}\mathcal{T}(A, T)$, где $\mathcal{T}$ - функция потерь.

Очевидно, что если $\mathbb{X} = \mathbb{U} \times \mathbb{I}, \mathbb{Y} = \{-1, +1\}$, а
 $(u, i, +1) \in \mathbb{L},$ где $(u, i) \in \mathbb{U} \times \mathbb{I}$ имеет смысл "пользователь $u$ хорошо оценил товар $i$ ", то решив задачу бинарной классификации можно оценить вероятность того, что пользователь хорошо оценит какой-либо другой товар. Иными словами, в качестве функции $getScore$ в Алг. $\ref{alg:GENERALRS}$ может выступать функция, возвращающая результаты работы бинарного классификатора.

Наиболее распространёнными классификаторами являются:
\begin{itemize}
\item линейные ($A(x) = <w, x> + w_0$, где $w \in \mathbb{R}^n, w_0 \in R$)
\item нелинейные (напр. деревья решений)
\item нейронные сети
\item другие.
\end{itemize}

Т.к. нейронные сети обычно не используются для построения рекомендательных систем, не будем рассматривать алгоритм вычисления вклада признака для нейронных сетей. Рассмотрим алгоритмы вычисления вклада признака для одного линейного алгоритма и одного нелинейного.
\section{Вычисление вклада признака в рейтинг}
\subsection{Factorization Machines}
\subsubsection{Обзор метода}
На протяжении долгого времени, одним из самых популярных алгоритмов машинного обучения был метод опорных векторов (SVM) \cite{Svm} , однако, SVM не нашел широкого применения в задачах коллаборативной фильтрации, т.к. не способен построить надежную нелинейную разделяющую гиперповерхность, опираясь на сильно разреженные данные. В задачах данного типа хорошо зарекомендовали себя методы, основывающиеся на идее матричной/тензорной факторизации, например, PARAFAC \cite{Parafac}. С другой стороны, модели на основе матричной факторизации сильно ограничивают тип входных данных и не могут быть применены к стандартным векторам признаков. Т.е. данные модели не позволяют использовать все знания про объекты предметной области, которыми мы обладаем.

Модель FM является SVM с полиномиальным ядром (см. kernel trick) с одним важным отличием: коэффициенты представляются в факторизованном виде (т.е. в виде пары векторов $v, u$, таких что $<u,v> = a \in \mathcal{R}$) \cite{Fm}.

Модельное уравнение для FM 2-го порядка (модель более высоких порядков не имеют практической ценности):
\begin{equation}
\tilde{y}(x) = w_0 + \sum_{i=1}^{n}w_ix_i + \sum_{i=1}^{n}\sum_{j=i+1}^{n}<v_i, v_j>x_ix_j,
\end{equation}
где $w_0 \in \mathfrak{R}, w \in \mathfrak{R}^n, V \in \mathfrak{R}^{n \times k}$ - параметры модели, которые необходимо подобрать.
\begin{itemize}
\item $w_0$ --- общее смещение модели (вероятность, что случайное приложение понравится случайному пользователю)
\item $w_i$ --- вес $i$-й компоненты вектора признаков $x$ в данной модели
\item $v_i$ --- вещественный вектор размера $k$, описывающий $i$-й компонент вектора признаков. $k$ -  входной параметр алгоритма, описывающий глубину факторизации
\item $\tilde{w}_{i,j} = <v_i, v_j>$ --- вес взаимодействия $i$-й и $j$-й компоненты вектора признаков. Основной особенностью FM является то, что вместо прямого использования $\tilde{w}_{i,j}$ как параметра модели, используется их факторизованное представление. Именно это позволяет методу работать с сильно разреженными данными.
\end{itemize}

Подбор параметров модели ($w_0, w, V$) осуществляется с помощью различных алгоритмов стохастической оптимизации, например, SGD, ASGD, ALS.

\subsubsection{Оценка вклада признака}
Заметим, что более правильной оценкой было бы использовать величину $A(x) - A_{f_k}(x)$, где алгоритм $A_{f_k}$ имеет структуру аналогичную $A$, но на этапе обучения (подбора параметров) не использовался признака $f_k$. Однако, подбор параметров для каждого алгоритма - длительный процесс и подобрать параметры для $n$ алгоритмов (где $n$ - число признаков) на практике не представляется возможным. Поэтому будем использовать оценку данной величины.

Рассмотрим решающую функцию для FM-второго порядка:
\begin{equation*}
\tilde{y}(x) = w_0 + \sum_{i=1}^{n}w_ix_i + \sum_{i=1}^{n}\sum_{j=i+1}^{n}<v_i, v_j>x_ix_j.
\end{equation*}

Предположим, что нас интересует вклад, который вносит признак $x_k$ в значение $\tilde{y}(x)$. Для этого сгруппируем все члены, стоящие при $x_k$ :

\begin{equation*}
\tilde{y}(x) = w_0 + \sum_{i=1, i \neq k}^{n}w_ix_i + \sum_{i=1, i \neq k}^{n}\sum_{j=i+1, j \neq k}^{n}<v_i, v_j>x_ix_j + x_k \sum_{i = 1}^{n}<v_k, v_i>x_i.
\end{equation*}

Очевидно, что значение признака $x_k$ влияет только на последнее слагаемое, предлагается использовать данную величину как оценку вклада, вносимого данным признаком в оценку рейтинга:
%% дак как же все-таки у Вас оценка рейтинга будет обозначаться?
\begin{equation*}
\delta A_{f_k, j, u} = f_k(j, u) \sum_{i = 1}^{n}<v_k, v_i>f_i(j, u),
\end{equation*}
где $j \in \mathbb{I}$ - товар, $u \in \mathbb{U}$ - пользователь, f - признаковое описание для пары пользователь-товар.


\subsection{Деревья принятия решений}
Дерево принятия решений - это бинарное дерево, у которого в узлах (не являющихся листами) находятся предикаты, связанные с признаками, а в листьях - значение целевой функции (например, для задачи бинарной классификации - вероятность принадлежности выделенному классу), а каждое ребро ассоциировано с конкретным значением предиката, находящегося в родительском узле \cite{Dt}.
Таким образом, дерево принятия решений является кусочно-постоянной функцией. т.к. разбивает пространство признаков на некоторое конечное число областей, внутри которых значение целевой функции считается константным. На Рис. $\ref{ris:dt}$ приведен пример дерева принятия решений и области, в пространстве признаков, где целевая функция считается постоянной.

\begin{figure}[H]
\center{\includegraphics[width=0.8\linewidth]{dt}}
\caption{Пример дерева принятия решений}
\label{ris:dt}
\end{figure}

\subsection{Забывчивые деревья принятия решений}
Рассмотрим подмножество деревьев принятия решений, называемое забывчивыми деревьями принятия решений \cite{Ot}.
Основным отличием забывчивых деревьев является то, что 
%% если на каждом уровне "одно и то же условие" => все предикаты в узлах этого уровня совпадают! тогда само дерево не нужно строить
%! не совсем понял, что Вы имеете в виду. Дерево у которого на каждом уровне стоит один тот же предикат ничем не хуже других деревьев, просто частный случай... Если признаки независимы, то велика вероятность того, что строя произвольное дерево решений (напр., с помощью алгоритма C4.5) получится забывчивое дерево (про независимость признаков - это для примера, что бы пояснить, что забывчивые деревья могут получаться естественным путем, в работе независимость признаков не предполагается, т.к. это слишком сильное допущение). Да, их можно представлять более эффективно, как пару из массива предикатов и массива значений, о чем я говорю далее. Но рассуждать о них, как об обычных деревьх крайне удобно.
на каждом уровне дерева используется одно и тоже условие. 

\begin{figure}[H]
\center{\includegraphics[width=0.8\linewidth]{ot}}
\caption{Пример забывчивого дерева принятия решений}
\label{ris:ot}
\end{figure}

Безусловно это ограничение делает данный вид деревьев менее вариативными, что должно негативно влиять на качество классификации. Однако такая структура дерева позволяет эффективно хранить обученные деревья, а так же быстро вычислять значения целевой функции.

Закодируем путь из корня до каждого листа следующим образом: каждый переход по ребру, ассоциированному с истинностью условия будем обозначать за 1, а переход по ложному ребру за 0. Т.о. путь до каждого листа можно закодировать строкой длины $(d-1)$, состоящей из 0 и 1, где $d$ -- глубина дерева. Будем интерпретировать строку, сопоставленную каждому листу, как запись некоторого двоичного числа, тогда каждому листу будет сопоставлено натуральное число от 1 до $2^{d-1}$.
Таким образом значения каждого листа можно записать в массив длинной $2^{d-1}$ на позицию, ассоциированную с данным листом. Если так же записать массив из $(d-1)$ бинарных предикатов, то этого будет достаточно, что бы однозначно восстановить дерево.
Т.е. каждое забывчивое дерево можно формально представить в виде пары $(\{Condition\}_{i=0}^{d - 2}, \{Score\}_{i=0}^{2^{d - 1} - 1})$, где $\{Condition\}_{i=0}^{d - 2}$ - индексированное множество условий, $\{Score\}_{i=1}^{2^{d - 1}}$ - индексированное множество значений целевой функции.

Вычисление значений целевой функции для забывчивых деревьев крайне эффективно, достаточно составить бинарное число, у которого на месте $i$-го разряда будет стоять значение предиката $Condition_i$ и вернуть элемент массива $Score$ с данным индексом.

Благодаря эффективности вычисления значения целевой функции данный вид деревьев широко применяется на практике в составе ансамблей решений, которые будут рассмотрены далее.

\subsubsection{Оценка вклада признака}
Классификатор, используемы в данной работе, построен с использованием забывчивых деревьев, поэтому рассмотрим алгоритм оценки вклада признака в рейтинг для анного типа деревьев. Однако, данный подход может быть адаптирован для произвольных деревьев решений.

Очевидно, что подход с занулением какого-либо признака, как в случае, с Factoriazation Machines не сработает. Попробуем удалить все узлы, условия в которых используют указанный признак.
%% это Вы вовремя напомнили, до сих мест об этом обстоятельстве ни слова
% %Напомню, что в данной работе рассматриваются исключительно забывчивые деревья, однако, данные рассуждения можно модифицировать для произвольных деревьев решений.
%! и правда, лучше переформулировать

Пусть дано забывчивое дерево $Tree = (\{Condition\}_{i=0}^{d - 2}, \{Score\}_{i=0}^{2^{d - 1} - 1})$ высоты $d$.
Представим, что $Tree_{f_k}$ - так же является забывчивым деревом, построенным на $\{Condition\}_{i=0, i \neq k}^{d - 2}$ по тем же данным, что и $Tree$. Тогда
\begin{equation*}
\delta A_{f_k, j, u} = Tree(f(j, u)) - Tree_{f_k}(f(j, u)).
\end{equation*}

Введем операцию удаления условия, определенную для забывчивых деревьев:

\begin{algorithm}[H]
\SetAlgoLined
\KwData{$OriginTree = (Conditions, Leaves)$ - оригинальное дерево, представленное парой условия-решения, $f_k \in \mathbb{F}$ - признак, который надо исключить из рассмотрения}
\KwResult{ $TruncatedTree_{f_k}$ - новое дерево, построенное на основе $OriginTree$, но игнорирующее признак $f_k$}
$depth = len(Conditions)$ -- сохраняем оригинальную глубину дерева

$idx = findFeature(Conditions, f_k)$ -- ищем индекс условия, использующего признак $f_k$, если условий несколько, то возвращаем индекс первого

\eIf{$idx \ge 0$} {
	$newConditions = remove(Conditions, idx)$ -- удалим найденное условие из списка используемых в новом дереве
	
	\For{$j \in [0, 2^{depth-1} - 1]$} { -- заполним массив newScores
	
		$idxLeft = insertBit(j, idx, 0)$ -- операция $insertBit(n, i, b)$ вставляет бит $b$ в число $n$ на позицию $i$, при этом длина числа в битовом представлении увеличивается на 1
		
		$idxRigth = insertBit(j, idx, 1)$
		
		$newLeaves[j] = merge(Leaves(idxLeft), Leaves(idxRigth))$
		
		\textbf{return} $RemoveFeature((newConditions, newLeaves), f_k)$
	}
} {
	\textbf{return} ((Conditions, Leaves)
}
\caption{Процедура удаления условия из забывчивого дерева принятия решений.}
\label{alg:ROTN}
\end{algorithm}

Алг. $\ref{alg:ROTN}$ последовательно перебирает условия, использующие признак $f_k$ и удаляет их из списка используемых условий. После очередного удаления каждой возможной комбинации условий соответствует ровно 2 листа, которые объединяются с помощью процедуры $merge$, т.о. после каждого шага алгоритма получается валидное забывчивое дерево. Алгоритм останавливается, когда условий, использующих признак $f_k$ не осталось.

Процедуру $merge$ можно реализовать разными способами, например, как среднее между значениями в объединяемых листах. Однако, если во время подбора параметров в листах так же хранить число точек обучающего множества, попавших в данный лист, то получится Алг. $\ref{alg:MLFS}$.

\begin{algorithm}[H]
\SetAlgoLined
\KwData{$L1, L2$ - два листа дерева}
\KwResult{$L$ - объединенный лист}
$PointsInL1 = getPoints(L1)$ - количество точек обучающего множества, попавших в лист $L1$

$PointsInL2 = getPoints(L1)$

$TotalPoints = PointsInL1 + PointsInL2$

$TotalScore = \frac{PointsInL1}{TotalPoints}getScore(L1) + \frac{PointsInL2}{TotalPoints}getScore(L2)$

\textbf{return} $(TotalScore, TotalPoints)$
\caption{Процедура merge - объединения двух листов.}
\label{alg:MLFS}
\end{algorithm}

\subsection{Ансамбли решений}
%% нет, Вы все-таки наведите порядок с нотацией! так нельзя, чтобы семантика переменных изменяется по ходу изложения как перчатки!
Пусть $\mathbb{H}$ - некоторое семейство базовых алгоритмов классификации (или восстановления регрессии), каждый элемент $h(x; a) \in \mathbb{H} : X \to \mathbb{R}$ определяется некоторым вектором параметров $a \in \mathbb{A}$.

Предположим, что дано $m$ (для простоты, $m$ - не четное) независимых классификаторов $\{h(x, a_i)\}_{i=1}^m$ и для каждого классификатора вероятность ошибиться составляет $p < 0.5$.	Построим классификатор, опрашивающий все $m$ базовых классификатора и возвращающий ответ, принятый большинством. Тогда вероятность ошибки для такого классификатора составляет: $P = \sum_{i = m/2 + 1}^m \binom{m}{i}p^{i}(1-p)^{m-i}$. Например, при $m=25$ и $p=0.35$ $P=0.06$.

К сожалению, на практике такие результаты недостижимы, т.к. обычно результаты работы различных классификаторов сильно коррелированы, но идея комбинирования нескольких "плохих" классификаторов в один "хороший" крайне популярна.

\begin{Def}
Алгоритм $F(x) = \sum_{i=0}^{M}b_ih(x,a_i), b_m \in \mathbb{R}, a_i \in \mathbb{A}$ будем назвать ансамблем решений \cite{En}.
\end{Def}
При правильном подборе параметров ансамбли решений способны показывать результаты, многократно превосходящие результаты любого из базовых алгоритмов.


Базовые алгоритмы принято называть $\textit{слабыми решениями}$, а сам ансамбль - $\textit{сильным решением}$.
Заметим, что в качестве слабых решений можно использовать различные алгоритмы одновременно , например, SVM и деревья решений. Однако, на практике такой подход применяется крайне редко.

В данной работе, в качестве конкретной реализации ансамблей решений, будут рассмотрены ансамбли забывчивых деревьев решений, т.к. они наилучшим образом проявили себя при построении рассматриваемой рекомендательной системы.

\subsubsection{Оценка вклада признака}
Пусть дан ансамбль решений $Ensemble$, для определенности будем считать, что в качестве слабых решений используются забывчивые деревья.

Представим алгоритм для вычисления вклада признака $f_k$ в случае ансамбля забывчивых деревьев:

\begin{algorithm}[H]
\SetAlgoLined
\KwData{$Ensemble = \{(Tree_i, c_i)\}_{i=0}^M$- ансамбль забывчивых деревьев, $x$ - признаковое описание объекта, $f_k$ - признак}
\KwResult{$c_{f_i}(x)$}

$Ensemble_{f_k} = \emptyset$

\For{$(Tree, c) \in Ensemble$} {

	$Ensemble_{f_k} \leftarrow (removeFeature(Tree, f_i), c)$ -- добавляем новое дерево в ансамбль с удаленным признаком $f_k$
	
}

\textbf{return} $Ensemble(x) - Ensemble_{f_k}(x)$
\caption{Процедура вычисления величины $\delta A_{f_k, j, u}$ для ансамбля забывчивых деревьев}
\label{alg:CFIOT}
\end{algorithm}

\section{Сравнение вкладов различный признаков}
В предыдущем разделе были приведены конкретные алгоритмы для вычисления абсолютных вкладов различных признаков в итоговую оценку рейтинга некоторых выделенных рекомендательных систем. Теперь для решения исходной задачи необходимо привести реализацию функции $getMax$ из Алг. $\ref{alg:GENERALENT}$, т.е. необходимо предоставить алгоритм сравнения вкладов двух признаков.

\subsection{Наивный алгоритм}
Наивный подход заключается в том, что бы сравнивать непосредственно величины $\delta A_{f_k, j, u}$ и $\delta A_{f_l, j, u}$. Однозначно, данный подход имеет определенный физический смысл, однако он слишком груб. На практике, не все признаки одинаково "сильны", т.е. некоторые признаки обладают большей информативностью, чем другие, соответственно и вклад они вносят всегда больший.

С одной стороны это приводит к достаточно грубой оценке, с другой к малой вариативности объяснений.
Например, для рассматриваемой рекомендательной системы (которая будет описана далее), использование наивного подхода приводит к тому, что в 80\% случаев выбирается один из десяти признаков, хотя в вычислении рейтинга использовалось более 400 признаков.

\subsection{Оптимизация наивного алгоритма}
Введем гипотезу, что значение признака в данной рекомендации зависит не от абсолютного значения вклада признака в рейтинг (как в наивном подходе), а от того, насколько больше этот вклад в конкретном случае, чем в среднем. Т.е. предлагается сравнивать не абсолютные значения вклада в оценку рейтинга, а относительные приросты для каждого из признаков.
Такой подход позволяет нивелировать различную силу признаков и выделять именно те, которые дали максимальный для себя вклад в данном конкретном случае.

Будем рассматривать $\delta A_{f_k, i, u}$, как случайную величину с плотностью распределения $p(j, u)$.
В качестве первого приближения, предположим, что значения $\delta A_{f_k, i, u} \sim\mathcal{N}(\mu_{f_k}, \sigma_{f_k}^2)$.
Для оценки параметров $\mu_{f_i}, \sigma_{f_i}^2$ воспользуемся методом максимального правдоподобия \cite{Mle}, согласно которому:
\begin{equation*}
\begin{cases}
\tilde{\mu}_{f_i} = \overline{X} &\text{--- выборочное среднее} 
\\ \tilde{\sigma}_{f_i}^2 = \overline{S^2} &\text{ --- выборочная дисперсия}
\end{cases}
\end{equation*}
Выборку для оценки параметров можно получить с помощью вероятностного сэмплирования мн-ва $\mathbb{U} \times \mathbb{I}$.


\begin{algorithm}[H]
\SetAlgoLined
\KwData{$f$ - признаковое описание, $u \in \mathbb{U}$ - пользователь, $i \in \mathbb{I}$ - товар, $A$ - алгоритм классификации, $\mathbb{X} \subset \mathbb{U} \times \mathbb{I}$ - репрезентативная выборка пар пользователь-приложение}
\KwResult{ k - номер признака, вносящего наибольший положительный вклад}

$maxScore = 0$;

$idx = +\infty$

\For{$k = 1, \dots, FactorsCount$} {

// оцениваем параметры распределения вклада от $k$-го признака

$\tilde{\mu}_{f_k}, \tilde{\sigma}_{f_k}^2 = MaxLikelihood(\mathbb{X}, k)$

score = $\frac{\delta A_{f_k, i, u} - \tilde{\mu}_{f_k}}{\tilde{\sigma}_{f_k}}$

\If{$score > maxScore$}{

$idx = k$

$maxScore = score$

}
}

\textbf{return} $idx$
\caption{Псевдокод определения признака с наибольшим относительным вкладом.}
\label{alg:normalAI}
\end{algorithm}

\subsection{Отказ от гипотезы о нормальности распределения}
На рисунке $\ref{ris:contriball}$ представлены гистограммы вкладов различных признаков в итоговую вероятность. Выборка, использованная при построении данных гистограмм была получена с помощью вероятностного сэмплирования пространства $\mathbb{U} \times \mathbb{I}$. Размер выборки составляет порядка $10^5$ элементов.

Из Рис. $\ref{ris:contriball}$ становится очевидно, что нельзя считать $\delta A_{f_k, i, u} \sim \mathcal{N}(\mu_{f_i}, \sigma_{f_i}^2)$. Постараемся отказаться от каких-либо предположений о форме распределения величины $\delta A_{f_k, i, u}$.

\begin{figure}[pH]
\begin{minipage}[h]{0.49\linewidth}
\center{\includegraphics[width=0.8\linewidth]{182_distr} \\ а)}
\end{minipage}
\hfill
\begin{minipage}[h]{0.49\linewidth}
\center{\includegraphics[width=0.9\linewidth]{76_distr} \\ б)}
\end{minipage}
\begin{minipage}[h]{1.\linewidth}
\center{\includegraphics[width=0.9\linewidth]{16_distr} \\ в)}
\end{minipage}
\caption{Гистограммы вкладов различных признаков}
\label{ris:contriball}
\end{figure}

В рамках данного раздела, заменим обозначение $\delta A_{f_k, i, u}$ на $x$.
Предположим, что $x \sim \mathcal{F}_{X}$, где $\mathcal{F}_{X}$ - эмпирическая функция распределения с плотностью распределения $f$. Можно вычислить значение величины 
\begin{equation*}
p_{c_{f_k}} = \textit{P}\{X \le x\} \equiv \mathcal{F}_X(x) \equiv \int_{-\infty}^{x}f(x)dx \equiv 1 - \int_{x}^{+\infty}f(x)dx
\end{equation*}
и использовать ее для сравнения вкладов, вносимых различными признаками.

\begin{algorithm}[H]
\SetAlgoLined
\KwData{$\mathbb{F} = \{f_0, \dots f_{n}\}$ - мн-во признаков, $u \in \mathbb{U}$ - пользователь, $a \in \mathbb{I}$ - товар, $A$ - алгоритм классификации, $f$ - плотность распределения $\mathcal{F}_{X}$}
\KwResult{ k - индекс признака, вносящего наибольший положительный вклад}

$maxProb = 0$;

$idx = +\infty$

\For{$k = 1, \dots, n$} {

$curProb = 1 - \int_{x}^{+\infty}f(\delta A_{f_k, a, u})dx$

\If{$curProb > maxProb$}{

$idx = i$

$maxProb = curProb$

}
}

\textbf{return} $idx$
\caption{Определения признака с наибольшим относительным вкладом в случае произвольного распределения.}
\label{alg:AFAI}
\end{algorithm}

Заметим, что в том случае, когда $\mathcal{F} \sim \mathcal{N}(\mu, \sigma^2)$ алгоритмы \ref{alg:normalAI} и \ref{alg:AFAI} дают одинаковые результаты.

\subsubsection{Восстановление плотности распределения}
Попробуем приблизить искомое распределение с помощью смеси распределений:

\begin{equation*}
p(x) = \sum_{j=1}^{k}\omega_jp_j(x), \sum_{j=1}^{k}\omega_j = 1, \omega_j \ge 0, 
\end{equation*}
где $p_k(x, \theta_k)$ - функция правдоподобия $j$-й компоненты смеси, $\omega_j$ - ее априорная вероятность. Функции правдоподобия принадлежат параметрическому семейству распределений $\phi(x; \theta)$ и отличаются только значением параметра $p_j(x) = \phi(x; \theta_j)$.
Задача: зная число компонент смеси $k$, имея выборку $X^m$ случайных и независимых событий из смеси $p(x)$ и зная функцию $\phi$ оценить параметры $\Theta = (\omega_1, \dots, \omega_k, \theta_1, \dots, \theta_k)$.

Классическим подходом к решению данной задачи, является использование EM-алгоритма.

\textbf{E-шаг (expectation).}
Обозначим через $p(x, \theta_j)$ плотность вероятности того, что объект $x$ получен и $j$-й компоненты смеси. По формуле условной вероятности:
\begin{equation*}
p(x, \theta_j) = p(x)P(\theta_j|x) = \omega_jp_j(x).
\end{equation*} 

Введем обозначение $g_{ij} \equiv P(\theta_j|x_i)$ - апостериорная вероятность того, что объект $x_i$ получен из $j$-й компоненты смеси. Обозначим $G=(g_{ij})_{m \times k}$. Т.к. каждый объект принадлежит какой-либо компоненте:
\begin{equation*}
\forall i \in (1, \dots, m) \sum_{j=1}^{k}g_{ij} = 1.
\end{equation*}

Зная параметры компонент $\omega_j, \theta_j$, можно вычислить $g_{ij}$ по формуле Байеса:
\begin{equation*}
\forall i,j g_{ij} = \frac{\omega_jp_j(x_i)}{\sum_{s=1}^{k}\omega_sp_s(x_i)}.
\end{equation*}

\textbf{M-шаг (maximization).}
Постараемся максимизировать логарифм правдоподобия:
\begin{equation*}
Q(\Theta) = \ln \prod_{i=1}^{m}p(x_i) = \sum_{i=1}^{m}\ln \sum_{j=1}^{k} \omega_jp_j(x_i) \to \max_{\Theta}
\end{equation*}
при ограничении $\sum_{j=1}^{m} = 1$. Запишем Лагранжа данной оптимизационной задачи:
\begin{equation*}
L(\Theta, X^m) = \sum_{i=1}^{m}\ln (\sum_{j=1}^{k}\omega_jp_j(x_i)) - \lambda(\sum_{j=1}^{k}\omega_j - 1).
\end{equation*}
Приравняем производную лагранжиана по $\omega_j$ к нулю:
\begin{equation*}
\frac{\partial L}{\partial \omega_j} = \sum_{i=1}^{m} \frac{p_j(x_i)}{\sum_{s=1}^{k}\omega_sp_s(x_i)} -\lambda = 0, \forall j \in (1, \dots, k).
\end{equation*}
Умножим обе части на $\omega_j$, просуммируем все $k$ равенств и изменим порядок суммирования:
\begin{equation*}
\sum_{i=1}^{m}\sum_{j=1}^{k}\frac{\omega_jp_j(x_i)}{\sum_{s=1}^{k}\omega_sp_s(x_i)} = \lambda \sum_{j=1}^{k}\omega_j,
\end{equation*}
откуда следует, что $\lambda = m$. Учитывая этот факт:
\begin{equation*}
\omega_j = \frac{1}{m} \sum_{i=1}^{m}\frac{\omega_jp_j(x_i)}{\sum_{s=1}^{k}\omega_sp_s(x_i)]} = \frac{1}{m}\sum_{j=1}^m g_{ij}, \forall j \in (1, \dots, k).
\end{equation*}
Приравняем производную лагранжиана по $\theta_j$ к 0, понятно, что $p_j(x) \equiv \phi(x' \theta_j)$:
\begin{eqnarray}
\frac{\partial L}{\partial \theta_j} = \sum_{i=1}^{m} \frac{\omega_j}{\sum_{s=1}^{k}\omega_sp_s(x_i)} \frac{\partial }{\partial \theta_j} p_j(x_i) = 
\sum_{i=1}^{m} \frac{\omega_j p_j(x_i)}{\sum_{s=1}^{k}\omega_sp_s(x_i)} \frac{\partial }{\partial \theta_j} \ln p_j(x_i) = \\
\sum_{i=1}^{m}g_{ij} \frac{\partial }{\partial \theta_j} \ln p_j(x_i) = \frac{\partial }{\partial \theta_j} \sum_{i=1}^{m}g_{ij}  \ln p_j(x_i) = 0, \forall j \in (1, \dots, k).
\end{eqnarray}

Полученное условие совпадает с необходимым условием максимума в задаче максимизации взвешенного правдоподобия
\begin{equation*}
\theta_j = \arg \max_{\theta} \sum_{i=1}^{m}g_{ij}  \ln\phi(x_i; \theta).
\end{equation*}


\begin{algorithm}[H]
\SetAlgoLined
\SetKwRepeat{Do}{do}{while}
\KwData{$X^m = (x_1, \dots, x_m)$ - выборка, $k$ - число компонент в смеси, $\Theta=(\omega_j,\theta_j)_{j=1}^k$ - начальное приближение параметров смеси, $\delta$ - параметр критерия остановки}
\KwResult{$\Theta$ - оптимальный вектор параметров смеси}
\Do{$\max_{i,j}|g_{ij} - g_{ij}^0| > \delta$}{
\textbf{E-шаг:}

	\For{$i \in  (1, \dots, m), j \in  (1, \dots, k)$} {
		$g_{ij}^0 = g_{ij}$
		
		$g_{ij} = \frac{\omega_j \phi(x_i; \theta_j)}{\sum_{s=1}^{k} \omega_s \phi(x_i; \theta_s)}$
	}

	\textbf{M-шаг:}
	
	\For{$j \in  (1, \dots, k)$} {
		$\theta_j = \arg \max_{\theta} \sum_{i=1}^{m}g_{ij}  \ln\phi(x_i; \theta)$
	}
}

\textbf{return} $(\omega_j, \theta_j)_{j=1}^k$
\caption{Классический EM-алгоритм.}
\label{alg:EM}
\end{algorithm}

Приведенный алгоритм обладает рядом недостатков, одним из которых является знание числа компонент в смеси  $k$. Рассмотрим алгоритм, автоматически определяющий необходимое число компонент \cite{Kem}:

\begin{algorithm}[H]
\SetAlgoLined
\SetKwRepeat{Do}{do}{while}
\KwData{$X^m = (x_1, \dots, x_m)$ - выборка, $\delta$ - параметр критерия остановки, $R$ -  максимальный допустимый разброс правдоподобия, $m_0$ - минимальная длина выборки по которой можно восстановить плотность}
\KwResult{$k$ - число компонент, $\Theta$ - оптимальный вектор параметров смеси}

$\theta_1 =  \arg \max_{\theta} \sum_{i=1}^{m} \ln\phi(x_i; \theta)$ -- начальное приближение

$\omega_1 = 1, k = 1$

\For{$k \in (2, 3, \dots)$} {
	$\mathbb{U} = \{x_i \in X^m: p(x_i) < \max_j p(x_j) / R\}$ -- выбираем объекты с низким правдоподобием
	
	\If{$|\mathbb{U}| < m_0$} {
		\textbf{exit}
	}
	
	$\theta_k =  \arg \max_{\theta} \sum_{x_i \in \mathbb{U}} \ln\phi(x_i; \theta)$ -- начальное приближение для $k$-й компоненты
	
	$\omega_k = \frac{|\mathbb{U}|}{m}$
	
	$\omega_j = \omega_j(1-\omega_k), \forall j \in (1, \dots, k-1)$
	
	$EM(X^m, k, \Theta, \delta)$
}
\caption{EM-алгоритм с последовательным добавление компонент.}
\label{alg:KEM}
\end{algorithm}

Заметим, что минимизируемый функционал $Q(\Theta)$ может быть не выпуклым и иметь большое количество локальных экстремумов, что делает классический алгоритм сильно зависимым от качества начального приближения. Оптимизация, позволяющая значительно уменьшить роль начального приближения называется SEM (стохастический EM) \cite{Sem}.

Основным отличием SEM от классического EM является то, что вместо решения задачи максимизации взвешенного правдоподобия решается задача максимизации обычного, не взвешенного правдоподобия:
\begin{equation*}
\theta_j = \arg \max_{\theta} \sum_{x_i \in X^{(g_j)}} \ln \phi(x_i; \theta),
\end{equation*}
где подвыборка $X^{(g_j)}$ генерируется из $X^m$ с помощью стохастического моделирования: каждый объект $x_i \in X^m$ попадает в $X^{(g_j)}$ с вероятностью $g_{ij}$.

Еще одним важным отличием является способ подбора числа $k$. Данный алгоритм начинает работу с заведомо большего числа компонент, чем может оказаться в смеси. Далее после очередного шага все компоненты, для которых справедливо $|X^{(g_j)}| \le m_0$ удаляются и число $k$ соответственно уменьшается.

К основным преимуществам SEM относят:
\begin{itemize}
\item малое число итераций для сходимости;
\item результаты практически не зависят от начального приближения
\item как правило, находится экстремум, близкий к глобальному.
\end{itemize}

Т.к. в общем случае никаких гипотез о форме компонент смеси составить нельзя, будем искать результирующую плотность, как смесь нормальных плотностей. Результаты применения различных способов оценки плотности представлены на Рис.  $\ref{ris:cmp}$.

\begin{figure}[H]
\center{\includegraphics[width=0.8\linewidth]{cmp}}
\caption{Сравнение различных аппроксимаций плотности}
\label{ris:cmp}
\end{figure}


\chapter{Решения практической задачи}
\section{Задача рекомендации мобильных приложений}
Приведенные в данной работе методы будут встраиваться в рекомендательную систему для магазина мобильных приложения под платформу Android. Рекомендательная система, основывается на двух классификаторах: линейном (использующем Factorization Machines) и нелинейном (ансамбль забывчивых деревьев).

\subsection{Исходные данные}
Для магазина мобильных приложений все исходные данные можно разделить на 3 типа:
\begin{itemize}
\item данные про пользователей
\item данные про приложения
\item данные про пару пользователь - приложение (статистика использования конкретного приложения конкретным пользователем).
\end{itemize}
Данные про приложения можно получить из магазина приложений Google Play. К таким знаниям относятся:
\begin{itemize}
\item категория (игры, навигация, etc)
\item текстовое описание
\item комментарии пользователей
\item средняя оценка пользователей
\item кол-во установок
\item версии операционной системы, для которых доступно данное приложение
\item etc.
\end{itemize}
Так же можно извлечь данные из анонимной статистики, собираемой на устройствах пользователя:
\begin{itemize}
\item среднее время от открытия до закрытия приложения
\item распределение числа запусков по времени суток
\item кол-во установок и удалений за период времени
\item среднее время от установки на устройство пользователя до удаления
\item etc
\end{itemize}
Данные про пользователя можно извлечь как из статистики с устройства пользователя, так и анализируя поведение пользователя в магазине (в приложении или на веб-интерфейсе):
\begin{itemize}
\item список установленных приложений
\item установки/запуски/удаления приложений с привязкой ко времени и координатам
\item факт просмотра конкретного приложения в магазине
\item модель телефона
\item версия ОС
\item etc.
\end{itemize}

На основе перечисленных данных строится набор признаков, с помощью которого вычисляется признаковое описание для пары пользователь-приложение. Напомню, что признаковое описание объекта и сам объект отождествляются.

\subsection{Пример отображения $M$}
[ TODO ??? ]

\section{Предварительный анализ}
Прежде чем перейти непосредственно к сравнению результатов работы предложенных алгоритмов, проведём предварительный анализ значений, генерируемых с помощью рассмотренных алгоритмов.

При описании наивного алгоритма, была выдвинута гипотеза, что результаты могут быть слишком однообразными как из-за различной нормировки признаков, так и из-за различной априорной информативности. Что бы подтвердить данную гипотезу построим гистограмму, показывающую сколько признаков в какой доле случаев выделяются наивным алгоритмом.

\begin{figure}[H]
\center{\includegraphics[width=0.8\linewidth]{cmp1}}
\caption{Доля случаев, покрываемых n-признаками в случае наивного алгоритма}
\label{ris:dummycoverage}
\end{figure}

На Рис. $\ref{ris:dummycoverage}$ видно, 10 (из 415 рассмотренных) признаков способны покрыть более 80\% случаев.
Очевидно, что такие однообразные объяснения рекомендаций могут быстро надоесть пользователю и начать его раздражать, что приведет к немедленному ухудшению общего качества рекомендательной системы.

Рассмотрим аналогичные гистограммы для Алг. $\ref{alg:normalAI}$ и его SEM-модификации Алг. 
$\ref{alg:AFAI}$.

\begin{figure}[H]
\center{\includegraphics[width=0.8\linewidth]{cmp2}}
\caption{Доля случаев, покрываемых n-признаками в случае нормального алгоритма и EM-модификации}
\label{ris:normalcoverage}
\end{figure}

\section{Оценка качества рекомендательной системы}
В качестве показателей качества рекомендательной системы мобильных приложений можно выбрать различные величины. Общепринятой практикой является вычисления нескольких конверсий:
\begin{itemize}
\item $ClickRate = \frac{Clicks}{Shows}$ - доля показов приложения пользователю, которая привела к клику, переводящему на страницу установки.
\item $InstallRate = \frac{Installs}{Clicks}$ - доля переходов на страницу установки, завершившияхся установкой приложения.
\end{itemize}
Так же часто вычисляют величину $InstallPerShow = ClickRate * InstallRate$ - доля показов, окончившихся установкой приложения.
Очевидно, что чем больше каждая из этих величин, тем лучше работает рекомендательная система, однако, встает вопрос о корректном сравнении нескольких различных рекомендательных систем.
Например, даны 2 рекомендательные системы $A$ и $A'$. Система $A$ проработала один день и 3 из 100 сформированных рекомендаций привели к установке. На следующих день работала $A'$, показав результаты в 4 установки на 100 показов. Не смотря на то, что $A'$ имеет большую конверсию, относительно $A$, однозначно утверждать о превосходстве $A'$ над $A$ пока нельзя, т.к. нет уверенности, что наблюдаемые изменения конверсии статистически значимы.

Обычно рекомендательные системы сравнивают с помощью метрик (например, F1-мера), вычисляемых на исторических данных, не учувствовавших при подборе параметров (тестовое множество). Однако, данный подход не применим для сравнения двух рекомендательных систем, отличающихся только алгоритмом объяснения результатов, т.к. невозможно смоделировать реакцию пользователя на тот или иной сопроводительный текст. Поэтому, рассмотрим несколько подходов, обычно применяемых в задачах ранжирования, позволяющие сравнить две рекомендательные системы, основываясь на реакциях пользователей.

\subsection{A/B тестирование}
Пусть даны 2 рекомендательные системы $A$ и $A'$, а так же $\mathbb{U}$ - множество всех пользователей. Разобьем множество $\mathbb{U}$ случайным образом на 2 непересекающихся подмножества $\mathbb{A}$ и  $\mathbb{B}$ таким образом, что бы $\forall e \in U \textit{P}\{e \in \mathbb{A}\} = \textit{P}\{e \in \mathbb{B}\} = \frac{1}{2}$.
Для всех пользователей $a \in \mathbb{A}$ будем возвращать результаты, сформированные алгоритмом $A$, для остальных - сформированные алгоритмом $A'$ \cite{Ab}.

Подсчитаем интересующую нас конверсию за каждый день исследования для обоих алгоритмов. В итоге получатся 2 выборки: $a = (a_1, \dots, a_j)$ и $a' = (a'_1, \dots, a'_n)$ из распределений $F(x)$ и $G(x)$ соответственно.

Проверим нулевую гипотезу $\mathcal{H}_0: \textit{P}\{a < a'\} = 1/2$. Это можно сделать с помощью критерия Уилкоксона-Манна-Уитни \cite{Mw}.

Перед использованием данного критерия необходимо принять следующие гипотезы:
\begin{itemize}
\item выборки $a$ и $a'$ - простые, объединенная выборка независима.
\item распределения $F(x)$ и $G(x)$ непрерывны.
\end{itemize}
Других ограничений на распределения (например, симметричность) не накладывается.

Если гипотеза $\mathcal{H}_0$ принимается, то выводов о том, какой из алгоритмов лучше сделать нельзя, в противном случае, можно однозначно указать, какой из представленных алгоритмов лучше с точки зрения выбранной конверсии.

\subsection{Смешивание результатов}

Не всегда есть возможность равномерно разбить пользователей на 2 множества и возвращать им разные результаты. Альтернативным способом сравнения двух алгоритмов является использование в качестве рекомендаций, показываемых пользователю, смеси результатов работы обоих алгоритмов.

Пусть даны результаты работы двух различных алгоритмов формирования рекомендаций $A = (a_1, a_2, \dots)$ и $B = (b_1, b_2, \dots)$. Напомню, что $A$ и $B$ упорядочены по рейтингу (или вероятности установки). Очевидный подход к смешиванию результатов - сбалансированное смешивание \cite{In}.

\begin{algorithm}[H]
\SetAlgoLined
\KwData{$A, B$ - результаты работы различных алгоритмов формирования рекомендаций}
\KwResult{$I$ - результат после смешивания}
$I = \emptyset, k_a = 1, k_b = 1$

$AFirst = RandBit()$ -- определяем случайным образом приоритет у каждого результата

\While{$(k_a < |A|) \& (k_b < |B|)$}{
	\eIf{$(k_a < k_b) | ((k_a = k_b) \& (AFirst = 1))$}{
		\If{$A[k_a] \notin I$} {
			$I = I + A[k_a]$
		}
		$k_a = k_a + 1$
	}{
		\If{$B[k_b] \notin I$} {
			$I = I + B[k_b]$
		}
		$k_b = k_b + 1$
	}
}
\textbf{return} $I$
\caption{Сбалансированное смешивание (balanced Interleaving).}
\label{alg:BI}
\end{algorithm}

Такой подход к смешиванию результатов гарантирует, что среди $k$-лучших рекомендаций в $I$ всегда содержатся $k_a$-лучших рекомендаций из $A$ и $k_b$-лучших рекомендаций из $B$, при этом, $|k_a-k_b| \le 1$.

Предположим, что пользователь просматривает рекомендации снизу вверх [T. Joachims, L. Granka, B. Pan, H. Hembrooke, F. Radlinski, and G. Gay. Evaluating the accuracy of implicit feedback from clicks and query reformulations in web search. ACM Transactions on nformation], а число рекомендованных приложений, которое увидит пользователь $l$ - зафиксировано и заранее известно. Т.е. у пользователя есть $l$ различных возможностей для клика, а число приложений, сформированных с помощью алгоритма $A$ и $B$ одинаково. Если пользователь будет случайно кликать по всем представленным рекомендациям, то он имеет равные шансы кликнуть как на приложение, ассоциированное с алгоритмом $A$, так и на приложение, ассоциированное с $B$. Т.е. если мы будем наблюдать большее абсолютное число кликов по приложениям, подобранным алгоритмом $A$, чем по приложениям, подобранным алгоритмом $B$, то можно делать выводы об относительном качестве двух алгоритмов.

Оформим процедуру принятия решения в виде алгоритма \cite{Td}:


\begin{algorithm}[H]
\SetAlgoLined
\KwData{$A, B$ - результаты работы различных алгоритмов формирования рекомендаций, $I$ - результат BalanceInterleaving($A, B$), 
$(c_1,c_2,\dots)$ - номера приложений в выдаче $I$, по которым произошел клик}
\KwResult{$C$ - метка предпочтительного класса}
$l \approx c_{max} = \max\{c_1,c_2,\dots\}$ [ T. Joachims. Evaluating retrieval performance using clickthrough data. In J. Franke, G. Nakhaeizadeh, and I. Renz, editors, Text Mining. Physica Verlag, 2003]

$k = \min\{j: (i_{c_{max}} = a_j) | (i_{c_{max}} = b_j)\}$

$h_a = |{c_j: i_{c_j} \in (a_1, \dots, a_k)}|$

$h_b = |{c_j: i_{c_j} \in (b_1, \dots, b_k)}|$

\If{$h_a > h_b$} {
\textbf{return} 'A'
}
\If{$h_a < h_b$} {
\textbf{return} 'B'
}

\textbf{return} NULL

\caption{Алгоритм выбора предпочтительного алгоритма формирования рекомендаций для конкретной выдачи.}
\label{alg:CBI}
\end{algorithm}

Приведенный выше алгоритм позволяет апостериори понять, какой из использованных алгоритмов формирования рекомендаций.
Применим данную процедуру ко всему множеству известных данных, в результате получится выборка, содержащая метки алгоритмов формирования рекомендаций. Далее с помощью, например, биномиального теста можно определить, существуют ли различия между частотами появления меток различных алгоритмов. Если различия значимы, то алгоритм, чья метка имеет большую частоту признается лучшим.

Заметим, что аппроксимация числа приложений, которое увидит пользователь, в виде $l \approx c_{max} = \max\{c_1,c_2,\dots\}$, может потенциально приводить к смещенным результатам, в случае использования сбалансированного смешивания. Например, в случаях, когда алгоритмы возвращают очень похожие списки рекомендаций. Предположим, что $A = (a, b, c, d)$, а $B = (b, c, d, a)$, в случае сбалансированного смешивания, равновероятны два результата: $I=(a, b, c, d)$ или $I=(b, a, c, d)$. Заметим, что в обоих случаях, пользователь, равномерно кликающий на все приложения, создаст преимущество для алгоритма $B$.

Рассмотрим альтернативных алгоритм смешивания, не страдающий от указанной проблемы.


\begin{algorithm}[H]
\SetAlgoLined
\KwData{$A, B$ - результаты работы различных алгоритмов формирования рекомендаций}
\KwResult{$I$ - результат после смешивания}
$I = \emptyset, TeamA = \emptyset, TeamB = \emptyset$

\While{($\exists i : A[i] \notin I) \& (\exists j: B[j] \notin I)$} {
	\eIf{$(|TeamA| < |TeamB|) | ((|TeamA| = |TeamB|) \& (RandBit() = 1))$} {
		$k=\min_i\{i: A{i}\notin I\}$
		
		$I = I + A[k]$
		
		$TeamA = TeamA \cup \{A[k]\}$
	} {
		$k=\min_i\{i: B{i}\notin I\}$
				
		$I = I + B[k]$
		
		$TeamA = TeamA \cup \{B[k]\}$
	}
}
\textbf{return} $I, TeamA, TeamB$
\caption{Алгоритм двух капитанов (team-draft interleaving).}
\label{alg:BI}
\end{algorithm}

Основным отличием от сбалансированного смешивания является то, что очерёдность выбора элементов может случайным образом меняться, когда из $A$ и $B$ изъято по одинаковому кол-ву приложений.

Заметим, что теперь справедливы следующие равенства:
\begin{equation*}
h_a = |\{c_j: i_{c_j} \in TeamA\}|
\end{equation*}
\begin{equation*}
h_b = |\{c_j: i_{c_j} \in TeamB\}|
\end{equation*}

\section{Эксперименты}
В данном разделе будут представлены результаты различных экспериментов, призванных ответить на следующие вопросы:
\begin{itemize}
\item Подтверждается ли гипотеза о влияние объяснения на конверсию?
\item Подтверждается ли гипотеза о роли признака?
\item Какой из алгоритмов интерпретации результатов показывает наилучшие результаты?
\end{itemize}

\subsection{Сравнение с базовой рекомендательной системой}
Первым делом, необходимо проверить гипотезы о роли признака и влиянии объяснения на конверсию. Для этого проведем эксперимент, сравнивающий рекомендательную систему, не использующую объяснения, и эту же рекомендательную систему, но с включенным режимом объяснения рекомендаций. Т.е. рекомендации будут сгенерированы по одному и тому же алгоритму, единственное отличие - наличие объяснения.

Эксперимент будет проводиться с помощью A/B-тестирования, т.к. TDI в данном случае не применим из-за различного дизайна блоков с рекомендациями. В качестве алгоритма для формирования сравнения вкладов будет использоваться Алг. $\ref{alg:normalAI}$, использующий гипотезу о нормальности распределения вклада.

В процессе эксперимента, вычислялось отношение числа кликов по блокам с рекомендациями к числу активных пользователей за день. Эксперимент длился 2 недели, т.о. были сформированы 2 равномощные выборки $X$ и $Y$, состоящие из 14 элементов. Выборка $X$ составлена  для рекомендательной системы, использующей алгоритм объяснения рекомендаций, а $Y$ - для базовой рекомендательной системы. Конкретные значения выборок представлены в Табл. $\ref{tabular:normalvsbase}$.

\begin{table} [H]
\label{tabular:normalvsbase}
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
 & $X$ & Ранг $X$ & $Y$ & Ранг $Y$   \\
\hline
1&1.422&21&1.417&19\\
\hline
2&1.335&12&1.421&20\\
\hline
3&1.453&22&1.34&13\\
\hline
4&1.484&23&1.357&15\\
\hline
5&2.001&28&1.986&27\\
\hline
6&1.68&26&1.531&25\\
\hline
7&1.373&16&1.194&5\\
\hline
8&1.492&24&1.233&6\\
\hline
9&1.38&17&1.041&2\\
\hline
10&1.234&7&0.95&1\\
\hline
11&1.261&8&1.117&4\\
\hline
12&1.354&14&1.274&9\\
\hline
13&1.317&11&1.072&3\\
\hline
14&1.401&18&1.293&10\\
\hline
\end{tabular}
\end{center}
\caption{Выборки, сгенерированные в эксперименте}
\end{table}

Значение статистики Манна-Уитни $U_{emp} = 54$, а критическое значение критерия для уровня значимости $0.05$ составляет $U_{cr} = 55$ \cite{Mw}. Т. е. $U_{emp} < U_{cr}$, что означает статистическую значимость различий между выборками.

\begin{figure}[H]
\center{\includegraphics[width=0.8\linewidth]{exp1_baseline}}
\caption{Результаты эксперимента}
\label{ris:expbaseline}
\end{figure}

На Рис. $\ref{ris:expbaseline}$ представлен график, демонстрирующий результаты эксперимента. Из него видно, что в среднем рекомендательная система с объяснением рекомендаций показывает лучший результат. В среднем отклонение составило 6\%.

Из результатов проведенного эксперимента, можно сделать вывод о справедливости выдвинутых гипотез (о роли признака и влиянии объяснения).

\subsection{Сравнение нормального алгоритма и  EM-модификации}
Рассмотрим, насколько точность объяснения влияет на конверсию. Для этого проведем эксперимент, в котором будут участвовать 2 рекомендательные системы, одна из которых будет использовать нормальный алгоритм интерпретации, а другая - EM-модификацию (основанную на смеси гауссиан).

Проведем эксперимент с помощью TDI, т.к. данный метод требует меньших ресурсов для реализации. Сформируем выборки $X$ и $Y$ таким же образом, как и в предыдущем эксперименте. Выборка $X$ будет соответствовать рекомендательной системе, использующей EM-модификацию алгоритма сравнения вкладов, а $Y$ - рекомендательной системе, использующей гипотезу о нормальности. 

\begin{table} [H]
\label{tabular:normalvsemexp}
\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
 & $X$ & Ранг $X$ & $Y$ & Ранг $Y$   \\
  \hline
 1&1.421&6&1.243&1\\
 \hline
 2&1.532&19&1.424&8\\
 \hline
 3&1.471&9&1.42&5\\
 \hline
 4&1.624&28&1.476&11\\
 \hline
 5&1.581&26&1.514&16\\
 \hline
 6&1.531&18&1.306&2\\
 \hline
 7&1.472&10&1.423&7\\
 \hline
 8&1.544&22&1.549&23\\
 \hline
 9&1.516&17&1.318&3\\
 \hline
 10&1.54&21&1.534&20\\
 \hline
 11&1.58&25&1.603&27\\
 \hline
 12&1.572&24&1.42&5\\
 \hline
 13&1.497&12&1.511&13\\
 \hline
 14&1.512&14&1.513&15\\
 \hline
\end{tabular}
\end{center}
\caption{Выборки, сгенерированные в эксперименте}
\end{table}

Значение статистики Манна-Уитни $U_{emp} = 50$, что означает статистическую значимость отличий между выборками (при уровне значимости 0.05). 

\begin{figure}[H]
\center{\includegraphics[width=0.8\linewidth]{exp2_nve}}
\caption{Результаты эксперимента}
\label{ris:expnve}
\end{figure}

На Рис. $\ref{ris:expnve}$ представлен график, демонстрирующий отношение числа кликов к общему числу пользователей для рекомендательных систем, участвующих в эксперименте.

Из данного эксперимента можно сделать вывод, что уточнение рекомендаций так же приводит к положительному эффекту. Удалось увеличить наблюдаемую метрику примерно на 3\%.

\chapter{Охрана труда}
\section{Введение}
Охрана труда представляет собой систему законодательных актов, социально-экономических, организационных, технических и лечебно-профилактических мероприятий и средств, обеспечивающих безопасность, сохранение здоровья и работоспособности человека в процессе труда \cite{Oh}. Охрана труда выявляет и изучает возможные причины производственных несчастных случаев, профессиональных заболеваний, аварий, взрывов, пожаров и разрабатывает систему мероприятий и требований с целью устранения этих причин и создания, безопасных и благоприятных для человека условий труда. Полностью безопасных и безвредных производственных процессов не существует. Задача охраны труда – свести к  минимуму вероятность поражения или заболевания работающего с одновременным обеспечением комфорта при максимальной производительности труда.

Сложность стоящих перед охраной труда задач требует использования достижений и выводов многих научных дисциплин, прямо или косвенно связанных с задачами создания здоровых и безопасных условий труда. Так как главным объектом охраны труда является человек в процессе труда, то при разработке требований производственной санитарии используются результаты исследований ряда медицинских и биологических дисциплин. Особо тесная связь существует между охраной труда, научной организацией труда, инженерной психологией, технической эстетикой и эргономикой. Эргономика изучает трудовую деятельность в комплексе, в ней объединяются научные дисциплины, развивавшиеся прежде независимо друг от друга. 

Эргономика – научная дисциплина, изучающая трудовые процессы с целью создания оптимальных условий труда, что способствует увеличению его производительности, а также обеспечивает необходимые удобства и сохраняет силы, здоровье и работоспособность человека. В последние годы много новых идей возникло в связи с рассмотрением трудовой деятельности как процесса взаимодействия человека с машиной и более сложными системами управления. В связи с этим эргономику условно можно разделить на три подобласти: 
\begin{itemize}
\item Микро-эргономика – исследование и проектирование систем “человек – машина”. Сюда же включаются интерфейсы “человек-компьютер” (компьютер  рассматривается как часть машины) - как аппаратные интерфейсы, так и программные. Соответственно, “эргономика программного обеспечения” – это подраздел микро-эргономики. Сюда же относятся системы: “человек – компьютер – человек”, “человек – компьютер – процесс”, “человек – программа, ПО, ОС”.
\item Миди-эргономика – исследование и проектирование систем “человек – рабочая группа, коллектив, экипаж, организация”, “коллектив – машина”, “человек – сеть, сетевое сообщество”, “коллектив – организация”. Сюда входит и проектирование организаций, и планирование работ, и обитаемость рабочих помещений, и гигиена труда, и проектирование залов с дисплеями общего пользования, проектирование интерфейсов сетевых программных продуктов, и многое, многое другое. Исследуется взаимодействие на уровне рабочих мест и производственных задач.
\item Макро-эргономика – исследование и проектирование систем “человек – социум, общество, государство”, “организация - система организаций”.
\end{itemize}

Компьютер стал неотъемлемой частью жизни практически каждого человека. Сейчас сложно найти сферу деятельности, которая так или иначе не соприкасалась с вычислительными машинами. Комфортность труда и высокая производительность на рабочем месте оператора зависит от правильного выбора основного и вспомогательного оборудования, которое должно отвечать эргономическим требованиям. 

В создании благоприятных условий для повышения  производительности и уменьшения напряжения пользователя значительную роль играют факторы, характеризующие состояние окружающей  среды: размер и микроклимат помещения, уровень шума и вибрации в помещении.

\section{Психо-физиологические факторы}
В комплексе мероприятий по совершенствованию организации труда важная роль отводится внедрению научно-обоснованных режимов труда и отдыха, улучшению условий труда. Основная цель рационального труда и отдыха — поддержание работоспособности на оптимальном уровне. Необходимость чередования труда и отдыха обусловлена физио-логическими закономерностями и играет большую роль в поддержании трудового ритма. Работоспособность работника в течение рабочего дня не является величиной стабильной. Основные фазы работоспособности:
\begin{itemize}
\item вырабатывание и нарастающая работоспособность;
\item высокая, устойчивая работоспособность;
\item падение работоспособности в результате развивающегося утомления.
\end{itemize}

Оптимальный режим труда и отдыха должен включать паузы. При неблагоприятных условиях труда высокий уровень работоспособности составляет не менее 75\% рабочего времени. Период вырабатывания составляет не более 40 минут, а восстановительный период — не более 10-15 минут. Наибольшая работоспособность инженерно-технических работников наблюдается с 10 до 12 и с 16 до 18 часов. Рекомендуется делать перерывы по 8-10 минут каждые 2 часа в первой половине дня и 5-8 минут через каждый час во второй половине дня.

\section{Помещение}
Помещения с видеодисплейными терминалами (далее – ВДТ) и персональными электронно-вычислительными машинами (далее - ПЭВМ) должны иметь естественное и искусственное освещение \cite{Li}. Естественное освещение должно осуществляться через светопроемы, которые ориентированы преимущественно на север и северо-восток.

Расположение рабочих мест с ВДТ и ПЭВМ для взрослых пользователей в подвальных помещениях не допускается. Размещение рабочих мест с ВДТ и ПЭВМ во всех учебных заведениях и дошкольных учреждениях не допускается в цокольных и подвальных помещениях. В случаях производственной необходимости эксплуатация ВДТ и ПЭВМ в помещениях без естественного освещения может проводиться только по согласованию с органами и учреждениями Государственного санитарно – эпидемиологического надзора.

Площадь на одно рабочее место с ВДТ или ПЭВМ для взрослых пользователей должна составлять не менее 6,0 кв. м, а объем - не менее 20,0 куб. м. 

Производственные помещения, в которых для работы используются преимущественно ВДТ и ПЭВМ (диспетчерские, операторские, расчетные и др.), и учебные помещения (аудитории вычислительной техники, дисплейные классы, кабинеты и др.) не должны граничить с помещениями, в которых уровни шума и вибрации превышают нормируемые значения (механические цеха, мастерские, гимнастические залы и т.п.). Звукоизоляция ограждающих конструкций помещений с ВДТ и ПЭВМ должна отвечать гигиеническим требованиям и обеспечивать нормируемые параметры шума.

Помещения с ВДТ и ПЭВМ должны оборудоваться системами отопления, кондиционирования воздуха или эффективной приточно-вытяжной вентиляцией. Расчет воздухообмена следует проводить по избыткам тепла от машин, людей, солнечной радиации и искусственного освещения. Нормируемые параметры микроклимата, ионного состава воздуха, содержание вредных веществ в нем должны отвечать требованиям Санитарных правил. 

Для внутренней отделки интерьера помещений с ВДТ и ПЭВМ должны использоваться диффузно - отражающие материалы с коэффициентом отражения для потолка – 0,7 - 0,8; для стен – 0,5 - 0,6; для пола – 0,3 - 0,5. Полимерные материалы, используемые для внутренней отделки интерьера помещений с ВДТ и ПЭВМ, должны быть разрешены для применения органами и учреждениями государственного санитарно-эпидемиологического надзора. В дошкольных и всех учебных учреждениях, включая вузы, запрещается для отделки внутреннего интерьера помещений с ВДТ и ПЭВМ применять полимерные материалы (древесностружечные плиты, слоистый бумажный пластик, синтетические ковровые покрытия др.), выделяющие в воздух вредные химические вещества. 

Поверхность пола в помещениях эксплуатации ВДТ и ПЭВМ должна быть ровной, без выбоин, нескользкой, удобной для очистки и влажной уборки, обладать антистатическими свойствами.

\section{Микроклимат}
Микроклиматические условия устанавливаются ГОСТом 12.1.005-88 и СанПиНом 2.2.2.548-96. Оптимальные и допустимые параметры микроклимата приведены в Табл. $\ref{tabular:micro1}$ и Табл. $\ref{tabular:micro2}$ соответственно.

\begin{table} [H]
\label{tabular:micro1}
\begin{center}
\begin{tabular}{|p{0.15\linewidth}|p{0.15\linewidth}|p{0.15\linewidth}|p{0.15\linewidth}|p{0.15\linewidth}|}
\hline
Период года & Категория работ & Температура (град. C) & Относительная влажность (\%) & Скорость движения воздуха (м/с) \\
\hline
Холодный и переходный & Легкая 1а & 22 -- 24 & 40 -- 60 & 0,1 \\
\hline
Холодный и переходный & Легкая 1б & 21 -- 23 & 40 -- 60 & 0,1 \\
\hline
Теплый & Легкая 1а & 23 -- 25 & 40 -- 60 & 0,1 \\
\hline
Теплый & Легкая 1б & 22 -- 24 & 40 -- 60 & 0,2 \\
\hline
\end{tabular}
\end{center}
\caption{Оптимальные параметры микроклимата}
\end{table}

Примечания к Табл. $\ref{tabular:micro1}$:
\begin{itemize}
\item категории 1а относятся работы, производимые сидя и не требующие физического напряжения, при которых расход энергии составляет до 120 ккал/ч
\item к категории 1б относятся работы, производимые сидя, стоя или связанные с ходьбой и сопровождающиеся некоторым физическим напряжением, при которых расход энергии составляет от 120 до 150 ккал/ч
\end{itemize}

\begin{table} [H]
\label{tabular:micro2}
\begin{center}
\begin{tabular}{|p{0.15\linewidth}|p{0.15\linewidth}|p{0.15\linewidth}|p{0.15\linewidth}|p{0.15\linewidth}|}
\hline
Период года & Категория работ & Температура (град. C) & Относительная влажность (\%) & Скорость движения воздуха (м/с) \\
\hline
Холодный и переходный & Легкая & 19 -- 25 & $\le$ 75 & < 0,2 \\
\hline
Теплый & Легкая & Не более чем на $3^\circ$C выше средней температуры воздуха в 13 часов самого жаркого месяца, но не более $28^\circ$C & $24^\circ$C:<75
$25^\circ$C:<70
$26^\circ$C:<65
$27^\circ$C:<60
$28^\circ$C:<55
 & < 0,2 -- 0,5 \\
\hline
\end{tabular}
\end{center}
\caption{Допустимые параметры микроклимата}
\end{table}

\section{Уровень шума}
На рабочем месте пользователя источником шума является вычислительная машина, производящая постоянный шум. Шум предоставляет собой сочетание звуков, различных по интенсивности и частоте в частотном диапазоне 10-20 кГц, не несущих полезной информации. Шум вредно воздействует не только на органы слуха, но и на весь организм человека в целом через центральную нервную систему. Шум – причина преждевременного утомления, ослабления внимания, памяти. Во всех учебных и дошкольных помещениях с ВДТ и ПЭВМ уровень шума на рабочем месте не должен превышать 50 дБА. Шумящее оборудование (принтеры, сканеры, факсы и т.д.), уровни шума которого превышают нормированные, должно находиться вне помещения с ВДТ и ПЭВМ. 

Снизить уровень шума в помещениях с ВДТ и ПЭВМ можно использованием звукопоглощающих материалов с максимальными коэффициентами звукопоглощения в области частот 63 - 8000 Гц для отделки помещений (разрешенных органами и учреждениями Госсанэпиднадзора России). Дополнительным звукопоглощением служат однотонные занавеси из плотной ткани, гармонирующие с окраской стен и подвешенные в складку на расстоянии 15 - 20 см от ограждения. Ширина занавеси должна быть в 2 раза больше ширины окна.

\section{Рабочее место}
Под рабочим местом пользователя понимается не только стол, а пространство, где находится и работает человек, оснащенное необходимыми техническими средствами, в котором совершается трудовая деятельность. Организацией рабочего места называется система мероприятий по оснащению рабочего места средствами и предметами труда и их размещению в определенном порядке. 

В соответствии с требованиями эргономики, рабочее место должно быть приспособлено для конкретного вида деятельности и для работников определенной квалификации с учетом их физической и психических возможностей и особенностей. Конструкция рабочего места должна обеспечивать быстроту, безопасность, простоту и экономичность технического обслуживания в нормальных и аварийных условиях; полностью отвечать функциональным требованиям и предполагаемым условиям эксплуатации. При конструировании производственного оборудования необходимо предусматривать возможность регулирования отдельных его элементов с тем, чтобы обеспечивать оптимальное положение работающего. При организации рабочего места учитываются также антропометрические данные пользователя.

Схемы размещения рабочих мест с ВДТ и ПЭВМ должны учитывать расстояния между рабочими столами с видеомониторами (в направлении тыла поверхности одного видеомонитора и экрана другого видеомонитора), которое должно быть не менее 2,0 м, а расстояние между боковыми поверхностями видеомониторов - не менее 1,2 м. 

Рабочие места с ВДТ и ПЭВМ в залах электронно-вычислительных машин или в помещениях с источниками вредных производственных факторов должны размещаться в изолированных кабинах с организованным воздухообменом. Рабочие места с ВДТ и ПЭВМ при выполнении творческой работы, требующей значительного умственного напряжения или высокой концентрации внимания, следует изолировать друг от друга перегородками высотой 1,5 - 2,0 м. 

Оконные проемы в помещениях использования ВДТ и ПЭВМ должны быть оборудованы регулируемыми устройствами типа жалюзи, занавесей и др.

Шкафы, сейфы, стеллажи для хранения дисков, дискет, комплектующих деталей, запасных блоков ВДТ и ПЭВМ, инструментов следует располагать в подсобных помещениях, для учебных заведений - в лаборантских. При отсутствии подсобных помещений или лаборантских допускается размещение шкафов, сейфов и стеллажей в помещениях непосредственного использования ВДТ и ПЭВМ при соблюдении требований к площади помещений и требований.

Конструкция рабочего стола должна обеспечивать оптимальное размещение на рабочей поверхности используемого оборудования с учетом его количества и конструктивных особенностей (размер ВДТ и ПЭВМ, клавиатуры, пюпитра и др.). При этом допускается использование рабочих столов различных конструкций, отвечающих современным требованиям эргономики. Покрытие стола должно быть матовым (с коэффициентом отражения 20 – 50\%) и легко чиститься; углы и передняя грань столешницы должны быть закругленными. Параметры стола указаны в Табл. $\ref{tabular:stol}$.

\begin{table} [H]
\label{tabular:stol}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
& \multicolumn{2}{c|}{Высота стола над полом (мм)} \\
\cline{2-3}
\raisebox{1.5ex}[0cm][0cm]{Рост пользователя в обуви (см)}
& Поверхность стола & Пространство для ног, не менее \\
\hline
116 -- 130 & 520 & 400 \\
\hline
131 -- 145 & 580 & 520 \\
\hline
146 -- 160 & 640 & 580 \\
\hline
161 -- 175 & 700 & 640 \\
\hline
\end{tabular}
\end{center}
\caption{Высота рабочей поверхности стола для пользователей}
\end{table}

Рабочий стол должен иметь пространство для ног высотой не менее той, которая указана в Табл. 13., шириной - не менее 500 мм, глубиной на уровне колен - не менее 450 мм и на уровне вытянутых ног - не менее 650 мм. 

Клавиатуру следует располагать на поверхности стола на расстоянии 100 - 300 мм от края, обращенного к пользователю, или на специальной регулируемой по высоте рабочей поверхности, отделенной от основной столешницы.

Конструкция рабочего стула (кресла) должна обеспечивать поддержание рациональной рабочей позы при работе на ВДТ и ПЭВМ, позволять изменять позу с целью снижения статического напряжения мышц шейно-плечевой области и спины для предупреждения развития утомления. Тип рабочего кресла должен выбираться в зависимости от характера и продолжительности работы  с учетом роста пользователя (Табл. $\ref{tabular:stul}$). При длительной работе кресло должно быть массивным, при кратковременной – легкой конструкции, свободно отодвигающееся.

Рабочее кресло должен быть подъемно - поворотным и регулируемым по высоте и углам наклона сиденья и спинки, а также расстоянию спинки от переднего края сиденья, при этом регулировка каждого параметра должна быть независимой, легко осуществляемой и иметь надежную фиксацию.

\begin{table} [H]
\label{tabular:stul}
\begin{center}
\begin{tabular}{|p{0.2\linewidth}|c|c|c|c|c|}
\hline
& \multicolumn{5}{c|}{Рост пользователя в обуви (см)} \\
\cline{2-6}
\raisebox{1.5ex}[0cm][0cm]{Параметры стула}
& 116 -- 130 & 131 -- 145 &  146 -- 160 & 161 -- 175  & Более 175\\
\hline
Высота сиденья над полом (мм) & 300 & 340 & 380 & 420 & 460 \\
\hline
Глубина сиденья	& 270 & 290	& 320 & 340 & 360 \\
\hline
Ширина сиденья, не менее (мм) & 290	& 330 & 360 & 380 & 400 \\
\hline
Высота нижнего края спинки над сиденьем (мм) & 130 & 150 & 160 & 170 & 190 \\
\hline
Высота линии прогиба спинки, не менее (мм) & 280 & 310 & 330 & 360 & 400 \\
\hline
Высота линии прогиба спинки, не менее (мм) & 170 & 190 & 200 & 210 & 220 \\
\hline
Радиус изгиба переднего края сиденья (мм) & \multicolumn{5}{c|}{20 -- 50} \\
\hline
Угол наклона сиденья (град)	& \multicolumn{5}{c|}{0 -- 4} \\
\hline
Угол наклона спинки (град)	& \multicolumn{5}{c|}{95 -- 108} \\
\hline
Радиус спинки в пален, не менее (мм) & \multicolumn{5}{c|}{300} \\
\hline
\end{tabular}
\end{center}
\caption{Параметры рабочего кресла}
\end{table}

Поверхность сиденья, спинки и других элементов кресла должна быть полумягкой, с нескользящим, неэлектризующимся и воздухопроницаемым покрытием, обеспечивающим легкую очистку от загрязнений. 

Визуальные эргономические параметры ВДТ являются параметрами безопасности, и их неправильный выбор приводит к ухудшению здоровья пользователей. Все ВДТ должны иметь гигиенический сертификат, включающий, в том числе, оценку визуальных параметров. 

Конструкция ВДТ, его дизайн и совокупность эргономических параметров должны обеспечивать надежное и комфортное считывание отображаемой информации в условиях эксплуатации. Устройство ВДТ должна обеспечивать возможность фронтального наблюдения экрана путем поворота корпуса в горизонтальной плоскости вокруг вертикальной оси в пределах  30 градусов и в вертикальной плоскости вокруг горизонтальной оси в пределах   30 градусов с фиксацией в заданном положении. Дизайн ВДТ должен предусматривать окраску корпуса в спокойные мягкие тона с диффузным рассеиванием света. Корпус ВДТ и ПЭВМ, клавиатура и другие блоки и устройства ПЭВМ должны иметь матовую поверхность одного цвета с коэффициентом отражения 0,4 – 0,6 и не иметь блестящих деталей, способных создавать блики. На лицевой стороне корпуса ВДТ не рекомендуется располагать органы управления, маркировку, какие-либо вспомогательные надписи и обозначения. При необходимости расположения органов управления на лицевой панели они должны закрываться крышкой или быть утоплены в корпусе.

Для обеспечения надежного считывания информации при соответствующей степени комфортности ее восприятия должны быть определены оптимальные и допустимые диапазоны визуальных эргономических параметров. Визуальные эргономические параметры ВДТ и пределы их изменений, в которых должны быть установлены оптимальные и допустимые диапазоны значений, приведены в Табл. $\ref{tabular:visual}$.

\begin{table} [H]
\label{tabular:visual}
\begin{center}
\begin{tabular}{|p{0.3\linewidth}|c|c|}
\hline
& \multicolumn{2}{c|}{Пределы значений параметров} \\
\cline{2-3}
\raisebox{1.5ex}[0cm][0cm]{Наименование параметров}
& Минимум (не менее) & Максимум (не более) \\
\hline
Яркость знака (яркость фона), измеренная в темноте (кд/м2)	& 35 & 120 \\
\hline
Внешняя освещенность экрана (лк) & 100 & 250 \\
\hline
Уголовой размер знака (угл. мин.) & 16 & 60 \\
\hline
\end{tabular}
\end{center}
\caption{Допустимые визуальные эргономические параметры}
\end{table}

Примечание к Табл. $\ref{tabular:visual}$: угловой размер знака – угол между линиями, соединяющими крайние точки знака по высоте и глаз наблюдателя. Угловой размер знака определяется по формуле:  , где h – высота знака, l – расстояние от знака до глаза наблюдения.

При проектировании и разработке ВДТ сочетания визуальных эргономических параметров и их значения, соответствующие оптимальным и допустимым диапазонам, полученные в результате испытаний в специализированных лабораториях, аккредитованных в установленном порядке, и подтвержденные соответствующими протоколами, должны быть внесены в техническую документацию на ВДТ. При отсутствии в технической документации на ВДТ данных об оптимальных и допустимых диапазонах значений эргономических параметров эксплуатации ВДТ не допускается. 

Конструкция ВДТ должна предусматривать наличие ручек регулировки яркости и контраста, обеспечивающих возможность регулировки этих параметров от минимальных до максимальных значений. 

В целях обеспечения защиты от электромагнитных и электростатических полей допускается применение экранных фильтров, специальных экранов и других средств индивидуальной защиты, прошедших испытания в аккредитованных лабораториях и имеющих соответствующий гигиенический сертификат. Допустимые значения параметров излучений указаны в Табл. $\ref{tabular:electro}$.

Конструкция ВДТ и ПЭВМ должна обеспечивать мощность экспозиционной дозы рентгеновского излучения в любой точке на расстоянии 0,05 м от экрана и корпуса ВДТ, при любых положениях регулировочных устройств не должна превышать100 мкР/ч.


\begin{table} [H]
\label{tabular:micro1}
\begin{center}
\begin{tabular}{|p{0.6\linewidth}|c||}
\hline
Наименование параметров & Допустимое значение \\
\hline
Напряженность электромагнитного поля по электрической составляющей на расстоянии 50 см от видеомонитора	& 10 В/м \\
\hline
Напряженность электромагнитного поля по электрической составляющей на расстоянии 50 см от поверхности видеомонитора	& 0,3 А/м \\
\hline
Напряженность электростатического поля не должна превышать:	& \\
\hline
	Для взрослых пользователей	& 20 кВ/м \\
\hline
	Для детей дошкольных учреждений и учащихся средних специальных и высших учебных заведений & 15 кВ/м \\
\hline
Напряженность электромагнитного поля на расстоянии 40 см вокруг ВДТ по электрической составляющей должна быть не более:	& \\
\hline
	В диапазоне частот 5 Гц – 2 кГц	& 25 В/м \\
\hline
	В диапазоне частот 2 кГц – 400 кГц	& 2,5 В/м \\
\hline
Плотность магнитного потока должна быть не более: & \\
\hline
	В диапазоне частот 5 Гц – 2 кГц	& 250 нТл \\
\hline
	В диапазоне частот 2 кГц – 400 кГц	& 25 нТл \\
\hline
Поверхностный электростатический потенциал не должен превышать & 500 В \\
\hline
\end{tabular}
\end{center}
\caption{Допустимые значения параметров неионизирующих электромагнитных излучений}
\end{table}

Конструкция клавиатуры должна предусматривать: 
\begin{itemize}
\item исполнение в виде отдельного устройства с возможностью свободного перемещения
\item опорное приспособление, позволяющее изменять угол наклона поверхности клавиатуры в пределах от 5 до 15 градусов
\item высоту среднего ряда клавиш не более 30 мм
\item расположение часто используемых клавиш в центре, внизу и справа, редко используемых - вверху и слева
\item выделение цветом, размером, формой и местом расположения функциональных групп клавиш
\item минимальный размер клавиш - 13 мм, оптимальный - 15 мм
\item клавиши с углублением в центре и шагом 19  1 мм
\item расстояние между клавишами не менее 3 мм
\item одинаковый ход для всех клавиш с минимальным сопротивлением нажатию 0,25 Н и максимальным - не более 1,5 Н
\item звуковую обратную связь от включения клавиш с регулировкой уровня звукового сигнала и возможности ее отключения
\item 
\item 
\end{itemize}

При работе за ПЭВМ очень важно сохранять правильную осанку, при которой позвоночник будет отдыхать, а не напрягаться. В этом помогает хорошо подобранное рабочее кресло. Спинка кресла должна поддерживать нижнюю половину спины, но при этом не быть жестко закрепленной, чтобы не препятствовать движениям в процессе работы. Ноги должны большую часть времени стоять на полу полной ступней, согнуты чуть больше, чем под прямым углом. 

Голова должна быть немного наклонена вперед, это наиболее естественное состояние. Монитор необходимо установит так, чтобы расстояние от глаз пользователя до любой точки монитора было примерно одинаковое и составляло 50 – 70 см. 

При работе на клавиатуре руки не должны находиться на весу, а опираться на подлокотники. Клавиатура обязательно должна располагаться чуть ниже локтя. Угол, образуемый между плечом и предплечьем, должен составлять около 120 градусов. 

\section{Освещение}
Помещения с ВДТ и ПЭВМ должны иметь естественное и искусственное освещение. Естественное освещение должно осуществляться через светопроемы, ориентированные преимущественно на север и северо-восток. Рабочие места с видеотерминалами (ВДТ) и персональными электронно-вычислительными машинами (ПЭВМ) по отношению к световым проемам должны располагаться так, чтобы естественный свет падал сбоку, преимущественно слева.

Искусственное освещение в помещениях эксплуатации ВДТ и ПЭВМ должно осуществляться системой общего равномерного освещения. В производственных и административно - общественных помещениях, в случаях преимущественной работы с документами, допускается применение системы комбинированного освещения.

Освещенность на поверхности стола в зоне размещения рабочего документа должна быть 300 - 500 лк. Допускается установка светильников местного освещения для подсветки документов. Местное освещение не должно создавать бликов на поверхности экрана и увеличивать освещенность экрана более 300 лк. 

В качестве источников света при искусственном освещении должны применяться преимущественно люминесцентные лампы, так как у них высокая светоотдача (до 120лм/Вт и более), продолжительный срок службы (до 10 000ч.), малая яркость светящейся поверхности, близкий к естественному спектральный состав излучаемого света, что обеспечивает хорошую светопередачу. Допускается применение ламп накаливания в светильниках местного освещения. Светильники местного освещения должны иметь непросвечивающий отражатель с защитным углом не менее 40 градусов.

Общее освещение следует выполнять в виде сплошных или прерывистых линий светильников, расположенных сбоку от рабочих мест, параллельно линии зрения пользователя при рядном расположении ВДТ и ПЭВМ. При периметральном расположении компьютеров линии светильников должны располагаться локализовано над рабочим столом ближе к его переднему краю, обращенному к оператору. 

Для обеспечения нормируемых значений освещенности в помещениях использования ВДТ и ПЭВМ следует проводить чистку стекол оконных рам и светильников не реже двух раз в год и проводить своевременную замену перегоревших ламп.

\section{Электробезопасность}
Электробезопасность – система организационных и технических мероприятий и средств, обеспечивающих защиту людей от вредного и опасного воздействия электрического тока, электрической дуги, электромагнитного поля и статического электричества. При прохождении через организм, электрический ток оказывает следующие виды воздействий:
\begin{itemize}
\item термическое действие (выражается в ожогах отдельных участков тела, нагреве кровеносных сосудов, нервов и иных тканей)
\item электролитическое воздействие (выражается в разложении крови и других органических жидкостей в организме, что вызывает существенное изменение в их физико-химических составах)
\item биологическое действие (выражается в раздражении и возбуждении живых тканей организма, нарушением внутренних биоэлектрических процессов, протекающих в нормально действующем организме, и тесно связанных с его жизненными функциями)
\end{itemize}

К числу основных причин, вызывающих поражение электрическим током относятся: случайное прикосновение к токоведущим частям, или приближение к ним на опасное расстояние; появление напряжений на металлических не токоведущих частях электрооборудования в результате пробоя или ошибочного включения; появление напряжения на поверхности земли в результате стекания тока в землю.

В соответствии с правилами устройства электроустановок (ПУЭ) для защиты должна применяется хотя бы одна из следующих нормативных мер: малые напряжения; защитное заземление, зануление или отключение. Защитное заземление - это преднамеренное соединение с землёй или её эквивалентом металлических нетоковедущих частей электроустановок, которые могут оказаться под напряжением. Основной смысл данной меры защиты – создание параллельного пути с наименьшим сопротивлением, при контакте человека с корпусом во время пробоя. Недостатком защитного заземления является постоянное наличие напряжения на корпусе. Защитное заземление должно присутствовать во всех помещениях. Зануление - это преднамеренное соединение с нулевым защитным проводником. Так как возникают большие токи, то необходимы плавкие вставки, но вследствие медленности срабатывания (5-7 сек), они предназначены в основном для противопожарной защиты. Отключение – это использование специального устройства, приводящее в действие отключающий механизм за время меньшее 0.1 сек. 

Признаки электрической опасности помещения:
\begin{itemize}
\item Повышенная опасность: наличие токопроводящего пола, сырости (> 75\%) или токопроводящей пыли, повышенная температура воздуха (> $30^\circ$C), возможность одновременного прикосновения к металлическим частям электроустановок и заземлённым конструкциям
\item Особая опасность: особая влажность (~100\%, поверхности покрыты влагой), химически активная среда, могущая разрушать изоляцию, наличие электроустановок, эксплуатируемых на открытом воздухе
\end{itemize}
В зависимости от признаков электрической опасности помещения подразделяются на 3 класса: помещения без повышенной опасности (без признаков опасности), помещения повышенной опасности (если присутствует хотя бы один признак повышенной опасности), особо опасные помещения (присутствует хотя бы один признак особой опасности, или более одного признака повышенной опасности).

Заземлению и занулению подлежат все электроустановки во взрывоопасных помещениях, в помещениях повышенной и особой опасности при напряжениях свыше 36В и в других помещениях при напряжениях свыше 500В.

\section{Пожаробезопасность}
Согласно ГОСТ 12.1.004-91 существуют следующие опасные факторы:
\begin{itemize}
\item пламя и искры
\item повышенная температура окружающей среды
\item токсичные продукты горения и термического разложения
\item пониженная концентрация кислорода
\end{itemize}
Противопожарная защита обеспечивается следующими мерами:
\begin{itemize}
\item применение средств пожаротушения, установка сигнализации и устройств тушения, ограничивающих распространение пожара, мероприятия по эвакуации людей, наличие средств индивидуальной защиты и средств противодымной защиты
\item наличие противопожарных перегородок и отсеков, устройств автоматического отключения систем
\item планировка эвакуационных путей и выходов
\item оповещение людей
\item технические средства для эвакуации и спасения людей
\item наличие огнетушащих веществ
\end{itemize}

Пожарную опасность в ВЦ представляют носители информации, поэтому помещение должно быть оборудовано несгораемыми стеллажами и шкафами. Хранение перфокарт, лент, дисков должно производиться в металлических кассетах. Не допускается размещение складских помещений, а также пожаровзрывоопасных производств над и под залами ЭВМ, а также смежных с ними помещениях.

Система вентиляции ВЦ должна быть оборудована устройством, обеспечивающим автоматическое отключение ее при пожаре, а также огнедымозадерживающими устройствами.

Подача воздуха к ЭВМ для охлаждения должна осуществляться по самостоятельному воздуховоду. Присоединение этих воздуховодов к общему коллектору допускается только после огне- и дымозадерживающих клапанов.

Система электропитания ЭВМ должна иметь блокировку, обеспечивающую отключение ЭВМ в случае остановки системы кондиционирования и охлаждения. Промывка ячеек и других съемных устройств горючими жидкостями допускается только в специальных помещениях, оборудованных проточно-вытяжной системой.

В здании ВЦ должна быть предусмотрена автоматическая пожарная сигнализация. В залах ЭВМ, за подвесными потолками, в хранилищах информации, кладовых запасного оборудования необходимо устанавливать извещатели, реагирующие на дым. Во всех других помещениях ВЦ допускается установка типовых пожарных извещателей.

Для тушения возможных пожаров ВЦ необходимо оборудовать автоматическими установками объемного газового тушения с выводом огнегасительного вещества в кабельные каналы и потоки.

\chapter{Заключение}
В данной работе была рассмотрена и формализована задача объяснения рекомендаций, генерируемых абстрактной рекомендательной системой. Был предложен общий алгоритм для решения поставленной задачи, опирающийся на гипотезу о роли признака. Однако, для имплементации предложенного алгоритма было необходимо выполнить следующие пункты:
\begin{itemize}
\item представить алгоритм для вычисления вклада признака в оценку рейтинга конкретной рекомендации;
\item представить способ сравнения для вкладов, вносимых различными признаками;
\item привести пример отображения $\mathbb{F} \times \dots \mathbb{F} \to \mathbb{S}$ .
\end{itemize}

Для разработки алгоритма вычисления вклада признака в оценку рейтинга, была предпринята попытка рассмотреть рекомендательную систему как черный ящик. Данный подход позволил бы абстрагироваться от конкретной реализации рекомендательной системы и разрабатывать максимально общие алгоритмы. Однако, практически-значимые результаты получить не удалось, а существующие решения (см. feature selection) для поставленной задачи не применимы.

Для того, что бы рассматривать рекомендательную систему, как прозрачный ящик, был приведен обзор существующих подходов, к построению рекомендательных систем. На основании данного обзора, были выделены классы решающих функций, которые представляют интерес для задачи объяснения рекомендаций. Из каждого класса были выделены по одному конкретному представителю, имеющему практическую значимость для задачи рекомендации мобильных приложений (Factorization Machines, ансамбль забывчивых деревьев). Для выделенных представителей были предложены алгоритмы вычисления абсолютного вклада признака в оценку рейтинга рекомендации.

Было предложено несколько стратегий для сравнения вкладов от различных признаков. Наивный алгоритм, сравнивающий абсолютные значения вкладов, показал низкую вариативность на этапе предварительного анализа. Т.к. слишком однообразные объяснения могут вызвать раздражение пользователя, было принято решение не испытывать данный алгоритм на реальных пользователях.

Алг. $\ref{alg:normalAI}$, использующий гипотезу о нормальности распределения вкладов различных признаков и его EM-модификация, приближающая истинное распределение, как сумму гауссиан, хорошо показали себя на этапе предварительного анализа. Так что было принято провести 2 эксперимента, с участием реальных пользователей.

Первый эксперимент был направлен на подтверждение основных гипотез, выдвинутых в первой главе (гипотеза о роли признака и гипотеза о положительной роли сопроводительного текста). Для этого проводилось сравнение рекомендательной системы, не использующей алгоритм объяснения рекомендаций и рекомендательной системы, использующей Алг. $\ref{alg:normalAI}$. По результатам эксперимента, рекомендательная система, использующая объяснения рекомендаций показала результаты, превосходящие результаты базовой рекомендательной системы на 6\%. С помощью критерия Уилкоксона-Манна-Уитни была показана статистическая значимость различий между рекомендательными системами при уровне значимость $0.05$ Т.о. обе гипотезы подтвердились.

Во втором эксперименте сравнивалась рекомендательная система, использующая Алг. $\ref{alg:normalAI}$ и рекомендательная система, использующая Алг. $\ref{alg:AFAI}$ (ЕМ-модификация). По результатам эксперимента рекомендательная система, использующая EM-алгоритм показала результаты на 3\%, превосходящие результаты рекомендательной системы, использующей гипотезу о нормальности. Данные изменения так же являются статистически значимыми. Благодаря данному эксперименту, был сделан вывод, что более точные рекомендации положительно виляют на качество рекомендательной системы.

Дополнительно в ходе оценки качества рекомендаций выявлено, что формулировка сопроводительного текста так же вносит значительный вклад в качество рекомендательной системы, т.е. появляется еще одна альтернативная степень свободы для последующего улучшения качества рекомендаций.

\bibliographystyle{utf8gost705u}  %% стилевой файл для оформления по ГОСТу
\bibliography{biblio}  

\end{document}
